{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Aiotest Documentation Aiotest is a scalable load testing framework written in Python Aiotest Github Authors Hewei github mail: hewei1987@163.com License Open source licensed under the MIT license (see LICENSE file for details). Express one's thanks Aiotest is a rewrite of locust (based on python asyncio) that drops the TaskSet class, sets the API to be tested only through the User class, drops the Stats class, collects test data through Prometheus, drops the Web class, and presents test data through Grafana * locust.io","title":"Home"},{"location":"#aiotest-documentation","text":"Aiotest is a scalable load testing framework written in Python Aiotest Github","title":"Aiotest Documentation"},{"location":"#authors","text":"Hewei github mail: hewei1987@163.com","title":"Authors"},{"location":"#license","text":"Open source licensed under the MIT license (see LICENSE file for details).","title":"License"},{"location":"#express-ones-thanks","text":"Aiotest is a rewrite of locust (based on python asyncio) that drops the TaskSet class, sets the API to be tested only through the User class, drops the Stats class, collects test data through Prometheus, drops the Web class, and presents test data through Grafana * locust.io","title":"Express one's thanks"},{"location":"api/","text":"API Reference User class Source code in aiotest\\user.py class User ( metaclass = UserMeta ): host = None session = None wait_time = 1 weight = 1 task = None def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) async def on_start ( self ): \"\"\" Called when a User starts running. \"\"\" pass async def on_stop ( self ): \"\"\" Called when a User stops running (is canceled) \"\"\" if not self . session . closed : await self . session . close () self . session = None def start_user ( self ): self . task = asyncio . create_task ( self . start (), name = type ( self ) . __name__ ) async def stop_user ( self ): if not self . task . done (): self . task . cancel () await self . on_stop () async def start ( self ): \"\"\" Synchronization executes coroutines job from top to bottom \"\"\" try : try : await self . on_start () await asyncio . sleep ( self . wait_time ) except : await self . on_stop () raise while True : for job in self . jobs : await job ( self ) await asyncio . sleep ( self . wait_time ) except asyncio . CancelledError : await self . on_stop () raise except Exception as e : await events . user_error . fire ( runner = runners . global_runner , error = f \" { sys . exc_info ()[ 0 ] . __name__ } : { e } \" + \"\" . join ( traceback . format_tb ( sys . exc_info ()[ 2 ])) . strip ()) on_start ( self ) async Called when a User starts running. Source code in aiotest\\user.py async def on_start ( self ): \"\"\" Called when a User starts running. \"\"\" pass on_stop ( self ) async Called when a User stops running (is canceled) Source code in aiotest\\user.py async def on_stop ( self ): \"\"\" Called when a User stops running (is canceled) \"\"\" if not self . session . closed : await self . session . close () self . session = None start ( self ) async Synchronization executes coroutines job from top to bottom Source code in aiotest\\user.py async def start ( self ): \"\"\" Synchronization executes coroutines job from top to bottom \"\"\" try : try : await self . on_start () await asyncio . sleep ( self . wait_time ) except : await self . on_stop () raise while True : for job in self . jobs : await job ( self ) await asyncio . sleep ( self . wait_time ) except asyncio . CancelledError : await self . on_stop () raise except Exception as e : await events . user_error . fire ( runner = runners . global_runner , error = f \" { sys . exc_info ()[ 0 ] . __name__ } : { e } \" + \"\" . join ( traceback . format_tb ( sys . exc_info ()[ 2 ])) . strip ()) AsyncHttpUser class Represents an AsyncHttp \"user\" which is to be started and attack the system that is to be load tested. Source code in aiotest\\user.py class AsyncHttpUser ( User ): \"\"\" Represents an AsyncHttp \"user\" which is to be started and attack the system that is to be load tested. \"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . session = ClientSession ( base_url = self . host ) ClientTimeout class Source code in aiotest\\client.py @attr . s ( auto_attribs = True , frozen = True , slots = True ) class ClientTimeout : total : Optional [ float ] = None connect : Optional [ float ] = None sock_read : Optional [ float ] = None sock_connect : Optional [ float ] = None # pool_queue_timeout: Optional[float] = None # dns_resolution_timeout: Optional[float] = None # socket_connect_timeout: Optional[float] = None # connection_acquiring_timeout: Optional[float] = None # new_connection_timeout: Optional[float] = None # http_header_timeout: Optional[float] = None # response_body_timeout: Optional[float] = None # to create a timeout specific for a single request, either # - create a completely new one to overwrite the default # - or use http://www.attrs.org/en/stable/api.html#attr.evolve # to overwrite the defaults ClientSession class First-class interface for making HTTP requests. Source code in aiotest\\client.py class ClientSession : \"\"\"First-class interface for making HTTP requests.\"\"\" ATTRS = frozenset ( [ \"_base_url\" , \"_source_traceback\" , \"_connector\" , \"requote_redirect_url\" , \"_loop\" , \"_cookie_jar\" , \"_connector_owner\" , \"_default_auth\" , \"_version\" , \"_json_serialize\" , \"_requote_redirect_url\" , \"_timeout\" , \"_raise_for_status\" , \"_auto_decompress\" , \"_trust_env\" , \"_default_headers\" , \"_skip_auto_headers\" , \"_request_class\" , \"_response_class\" , \"_ws_response_class\" , \"_trace_configs\" , \"_read_bufsize\" , ] ) _source_traceback = None # type: Optional[traceback.StackSummary] _connector = None # type: Optional[BaseConnector] def __init__ ( self , base_url : Optional [ StrOrURL ] = None , * , connector : Optional [ BaseConnector ] = None , loop : Optional [ asyncio . AbstractEventLoop ] = None , cookies : Optional [ LooseCookies ] = None , headers : Optional [ LooseHeaders ] = None , skip_auto_headers : Optional [ Iterable [ str ]] = None , auth : Optional [ BasicAuth ] = None , json_serialize : JSONEncoder = json . dumps , request_class : Type [ ClientRequest ] = ClientRequest , response_class : Type [ ClientResponse ] = ClientResponse , ws_response_class : Type [ ClientWebSocketResponse ] = ClientWebSocketResponse , version : HttpVersion = http . HttpVersion11 , cookie_jar : Optional [ AbstractCookieJar ] = None , connector_owner : bool = True , raise_for_status : bool = False , read_timeout : Union [ float , object ] = sentinel , conn_timeout : Optional [ float ] = None , timeout : Union [ object , ClientTimeout ] = sentinel , auto_decompress : bool = True , trust_env : bool = False , requote_redirect_url : bool = True , trace_configs : Optional [ List [ TraceConfig ]] = None , read_bufsize : int = 2 ** 16 , ) -> None : if loop is None : if connector is not None : loop = connector . _loop loop = get_running_loop ( loop ) if base_url is None or isinstance ( base_url , URL ): self . _base_url : Optional [ URL ] = base_url else : self . _base_url = URL ( base_url ) assert ( self . _base_url . origin () == self . _base_url ), \"Only absolute URLs without path part are supported\" if connector is None : connector = TCPConnector ( loop = loop ) if connector . _loop is not loop : raise RuntimeError ( \"Session and connector has to use same event loop\" ) self . _loop = loop if loop . get_debug (): self . _source_traceback = traceback . extract_stack ( sys . _getframe ( 1 )) if cookie_jar is None : cookie_jar = CookieJar ( loop = loop ) self . _cookie_jar = cookie_jar if cookies is not None : self . _cookie_jar . update_cookies ( cookies ) self . _connector = connector self . _connector_owner = connector_owner self . _default_auth = auth self . _version = version self . _json_serialize = json_serialize if timeout is sentinel : self . _timeout = DEFAULT_TIMEOUT if read_timeout is not sentinel : warnings . warn ( \"read_timeout is deprecated, \" \"use timeout argument instead\" , DeprecationWarning , stacklevel = 2 , ) self . _timeout = attr . evolve ( self . _timeout , total = read_timeout ) if conn_timeout is not None : self . _timeout = attr . evolve ( self . _timeout , connect = conn_timeout ) warnings . warn ( \"conn_timeout is deprecated, \" \"use timeout argument instead\" , DeprecationWarning , stacklevel = 2 , ) else : self . _timeout = timeout # type: ignore[assignment] if read_timeout is not sentinel : raise ValueError ( \"read_timeout and timeout parameters \" \"conflict, please setup \" \"timeout.read\" ) if conn_timeout is not None : raise ValueError ( \"conn_timeout and timeout parameters \" \"conflict, please setup \" \"timeout.connect\" ) self . _raise_for_status = raise_for_status self . _auto_decompress = auto_decompress self . _trust_env = trust_env self . _requote_redirect_url = requote_redirect_url self . _read_bufsize = read_bufsize # Convert to list of tuples if headers : real_headers : CIMultiDict [ str ] = CIMultiDict ( headers ) else : real_headers = CIMultiDict () self . _default_headers : CIMultiDict [ str ] = real_headers if skip_auto_headers is not None : self . _skip_auto_headers = frozenset ( istr ( i ) for i in skip_auto_headers ) else : self . _skip_auto_headers = frozenset () self . _request_class = request_class self . _response_class = response_class self . _ws_response_class = ws_response_class self . _trace_configs = trace_configs or [] for trace_config in self . _trace_configs : trace_config . freeze () def __init_subclass__ ( cls : Type [ \"ClientSession\" ]) -> None : warnings . warn ( \"Inheritance class {} from ClientSession \" \"is discouraged\" . format ( cls . __name__ ), DeprecationWarning , stacklevel = 2 , ) if DEBUG : def __setattr__ ( self , name : str , val : Any ) -> None : if name not in self . ATTRS : warnings . warn ( \"Setting custom ClientSession. {} attribute \" \"is discouraged\" . format ( name ), DeprecationWarning , stacklevel = 2 , ) super () . __setattr__ ( name , val ) def __del__ ( self , _warnings : Any = warnings ) -> None : if not self . closed : if PY_36 : kwargs = { \"source\" : self } else : kwargs = {} _warnings . warn ( f \"Unclosed client session { self !r} \" , ResourceWarning , ** kwargs ) context = { \"client_session\" : self , \"message\" : \"Unclosed client session\" } if self . _source_traceback is not None : context [ \"source_traceback\" ] = self . _source_traceback self . _loop . call_exception_handler ( context ) def request ( self , method : str , url : StrOrURL , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP request.\"\"\" return _RequestContextManager ( self . _request ( method , url , ** kwargs )) def _build_url ( self , str_or_url : StrOrURL ) -> URL : url = URL ( str_or_url ) if self . _base_url is None : return url else : assert not url . is_absolute () and url . path . startswith ( \"/\" ) return self . _base_url . join ( url ) async def _request ( self , method : str , str_or_url : StrOrURL , * , name : str = None , params : Optional [ Mapping [ str , str ]] = None , data : Any = None , json : Any = None , cookies : Optional [ LooseCookies ] = None , headers : Optional [ LooseHeaders ] = None , skip_auto_headers : Optional [ Iterable [ str ]] = None , auth : Optional [ BasicAuth ] = None , allow_redirects : bool = True , max_redirects : int = 10 , compress : Optional [ str ] = None , chunked : Optional [ bool ] = None , expect100 : bool = False , raise_for_status : Optional [ bool ] = None , read_until_eof : bool = True , proxy : Optional [ StrOrURL ] = None , proxy_auth : Optional [ BasicAuth ] = None , timeout : Union [ ClientTimeout , object ] = sentinel , verify_ssl : Optional [ bool ] = None , fingerprint : Optional [ bytes ] = None , ssl_context : Optional [ SSLContext ] = None , ssl : Optional [ Union [ SSLContext , bool , Fingerprint ]] = None , proxy_headers : Optional [ LooseHeaders ] = None , trace_request_ctx : Optional [ SimpleNamespace ] = None , read_bufsize : Optional [ int ] = None , ) -> ClientResponse : # NOTE: timeout clamps existing connect and read timeouts. We cannot # set the default to None because we need to detect if the user wants # to use the existing timeouts by setting timeout to None. if self . closed : raise RuntimeError ( \"Session is closed\" ) ssl = _merge_ssl_params ( ssl , verify_ssl , ssl_context , fingerprint ) if data is not None and json is not None : raise ValueError ( \"data and json parameters can not be used at the same time\" ) elif json is not None : data = payload . JsonPayload ( json , dumps = self . _json_serialize ) if not isinstance ( chunked , bool ) and chunked is not None : warnings . warn ( \"Chunk size is deprecated #1615\" , DeprecationWarning ) redirects = 0 history = [] version = self . _version # Merge with default headers and transform to CIMultiDict headers = self . _prepare_headers ( headers ) proxy_headers = self . _prepare_headers ( proxy_headers ) try : url = self . _build_url ( str_or_url ) except ValueError as e : raise InvalidURL ( str_or_url ) from e skip_headers = set ( self . _skip_auto_headers ) if skip_auto_headers is not None : for i in skip_auto_headers : skip_headers . add ( istr ( i )) if proxy is not None : try : proxy = URL ( proxy ) except ValueError as e : raise InvalidURL ( proxy ) from e if timeout is sentinel : real_timeout : ClientTimeout = self . _timeout else : if not isinstance ( timeout , ClientTimeout ): real_timeout = ClientTimeout ( total = timeout ) # type: ignore[arg-type] else : real_timeout = timeout # timeout is cumulative for all request operations # (request, redirects, responses, data consuming) tm = TimeoutHandle ( self . _loop , real_timeout . total ) handle = tm . start () if read_bufsize is None : read_bufsize = self . _read_bufsize traces = [ Trace ( self , trace_config , trace_config . trace_config_ctx ( trace_request_ctx = trace_request_ctx ), ) for trace_config in self . _trace_configs ] for trace in traces : await trace . send_request_start ( method , url . update_query ( params ), headers ) timer = tm . timer () try : with timer : while True : url , auth_from_url = strip_auth_from_url ( url ) if auth and auth_from_url : raise ValueError ( \"Cannot combine AUTH argument with \" \"credentials encoded in URL\" ) if auth is None : auth = auth_from_url if auth is None : auth = self . _default_auth # It would be confusing if we support explicit # Authorization header with auth argument if ( headers is not None and auth is not None and hdrs . AUTHORIZATION in headers ): raise ValueError ( \"Cannot combine AUTHORIZATION header \" \"with AUTH argument or credentials \" \"encoded in URL\" ) all_cookies = self . _cookie_jar . filter_cookies ( url ) if cookies is not None : tmp_cookie_jar = CookieJar () tmp_cookie_jar . update_cookies ( cookies ) req_cookies = tmp_cookie_jar . filter_cookies ( url ) if req_cookies : all_cookies . load ( req_cookies ) if proxy is not None : proxy = URL ( proxy ) elif self . _trust_env : with suppress ( LookupError ): proxy , proxy_auth = get_env_proxy_for_url ( url ) req = self . _request_class ( method , url , params = params , headers = headers , skip_auto_headers = skip_headers , data = data , cookies = all_cookies , auth = auth , version = version , compress = compress , chunked = chunked , expect100 = expect100 , loop = self . _loop , response_class = self . _response_class , proxy = proxy , proxy_auth = proxy_auth , timer = timer , session = self , ssl = ssl , proxy_headers = proxy_headers , traces = traces , ) # Collect request data request_meta = {} request_meta [ \"request_name\" ] = name if name else url . path request_meta [ \"request_method\" ] = method # connection timeout try : async with ceil_timeout ( real_timeout . connect ): assert self . _connector is not None # requests start time request_meta [ \"start_time\" ] = default_timer () conn = await self . _connector . connect ( req , traces = traces , timeout = real_timeout ) except asyncio . TimeoutError as exc : raise ServerTimeoutError ( \"Connection timeout \" \"to host {} \" . format ( url ) ) from exc assert conn . transport is not None assert conn . protocol is not None conn . protocol . set_response_params ( timer = timer , skip_payload = method . upper () == \"HEAD\" , read_until_eof = read_until_eof , auto_decompress = self . _auto_decompress , read_timeout = real_timeout . sock_read , read_bufsize = read_bufsize , ) try : try : resp = await req . send ( conn ) try : await resp . start ( conn ) except BaseException : resp . close () raise except BaseException : conn . close () raise except ClientError : raise except OSError as exc : if exc . errno is None and isinstance ( exc , asyncio . TimeoutError ): raise raise ClientOSError ( * exc . args ) from exc self . _cookie_jar . update_cookies ( resp . cookies , resp . url ) # redirects if resp . status in ( 301 , 302 , 303 , 307 , 308 ) and allow_redirects : for trace in traces : await trace . send_request_redirect ( method , url . update_query ( params ), headers , resp ) redirects += 1 history . append ( resp ) if max_redirects and redirects >= max_redirects : resp . close () raise TooManyRedirects ( history [ 0 ] . request_info , tuple ( history ) ) # For 301 and 302, mimic IE, now changed in RFC # https://github.com/kennethreitz/requests/pull/269 if ( resp . status == 303 and resp . method != hdrs . METH_HEAD ) or ( resp . status in ( 301 , 302 ) and resp . method == hdrs . METH_POST ): method = hdrs . METH_GET data = None if headers . get ( hdrs . CONTENT_LENGTH ): headers . pop ( hdrs . CONTENT_LENGTH ) r_url = resp . headers . get ( hdrs . LOCATION ) or resp . headers . get ( hdrs . URI ) if r_url is None : # see github.com/aio-libs/aiohttp/issues/2022 break else : # reading from correct redirection # response is forbidden resp . release () try : parsed_url = URL ( r_url , encoded = not self . _requote_redirect_url ) except ValueError as e : raise InvalidURL ( r_url ) from e scheme = parsed_url . scheme if scheme not in ( \"http\" , \"https\" , \"\" ): resp . close () raise ValueError ( \"Can redirect only to http or https\" ) elif not scheme : parsed_url = url . join ( parsed_url ) if url . origin () != parsed_url . origin (): auth = None headers . pop ( hdrs . AUTHORIZATION , None ) url = parsed_url params = None resp . release () continue break # check response status if raise_for_status is None : raise_for_status = self . _raise_for_status if raise_for_status : resp . raise_for_status () # register connection if handle is not None : if resp . connection is not None : resp . connection . add_callback ( handle . cancel ) else : handle . cancel () resp . _history = tuple ( history ) for trace in traces : await trace . send_request_end ( method , url . update_query ( params ), headers , resp ) resp . request_meta = request_meta return resp except BaseException as e : # cleanup timer tm . close () if handle : handle . cancel () handle = None for trace in traces : await trace . send_request_exception ( method , url . update_query ( params ), headers , e ) raise def ws_connect ( self , url : StrOrURL , * , method : str = hdrs . METH_GET , protocols : Iterable [ str ] = (), timeout : float = 10.0 , receive_timeout : Optional [ float ] = None , autoclose : bool = True , autoping : bool = True , heartbeat : Optional [ float ] = None , auth : Optional [ BasicAuth ] = None , origin : Optional [ str ] = None , params : Optional [ Mapping [ str , str ]] = None , headers : Optional [ LooseHeaders ] = None , proxy : Optional [ StrOrURL ] = None , proxy_auth : Optional [ BasicAuth ] = None , ssl : Union [ SSLContext , bool , None , Fingerprint ] = None , verify_ssl : Optional [ bool ] = None , fingerprint : Optional [ bytes ] = None , ssl_context : Optional [ SSLContext ] = None , proxy_headers : Optional [ LooseHeaders ] = None , compress : int = 0 , max_msg_size : int = 4 * 1024 * 1024 , ) -> \"_WSRequestContextManager\" : \"\"\"Initiate websocket connection.\"\"\" return _WSRequestContextManager ( self . _ws_connect ( url , method = method , protocols = protocols , timeout = timeout , receive_timeout = receive_timeout , autoclose = autoclose , autoping = autoping , heartbeat = heartbeat , auth = auth , origin = origin , params = params , headers = headers , proxy = proxy , proxy_auth = proxy_auth , ssl = ssl , verify_ssl = verify_ssl , fingerprint = fingerprint , ssl_context = ssl_context , proxy_headers = proxy_headers , compress = compress , max_msg_size = max_msg_size , ) ) async def _ws_connect ( self , url : StrOrURL , * , method : str = hdrs . METH_GET , protocols : Iterable [ str ] = (), timeout : float = 10.0 , receive_timeout : Optional [ float ] = None , autoclose : bool = True , autoping : bool = True , heartbeat : Optional [ float ] = None , auth : Optional [ BasicAuth ] = None , origin : Optional [ str ] = None , params : Optional [ Mapping [ str , str ]] = None , headers : Optional [ LooseHeaders ] = None , proxy : Optional [ StrOrURL ] = None , proxy_auth : Optional [ BasicAuth ] = None , ssl : Union [ SSLContext , bool , None , Fingerprint ] = None , verify_ssl : Optional [ bool ] = None , fingerprint : Optional [ bytes ] = None , ssl_context : Optional [ SSLContext ] = None , proxy_headers : Optional [ LooseHeaders ] = None , compress : int = 0 , max_msg_size : int = 4 * 1024 * 1024 , ) -> ClientWebSocketResponse : if headers is None : real_headers : CIMultiDict [ str ] = CIMultiDict () else : real_headers = CIMultiDict ( headers ) default_headers = { hdrs . UPGRADE : \"websocket\" , hdrs . CONNECTION : \"upgrade\" , hdrs . SEC_WEBSOCKET_VERSION : \"13\" , } for key , value in default_headers . items (): real_headers . setdefault ( key , value ) sec_key = base64 . b64encode ( os . urandom ( 16 )) real_headers [ hdrs . SEC_WEBSOCKET_KEY ] = sec_key . decode () if protocols : real_headers [ hdrs . SEC_WEBSOCKET_PROTOCOL ] = \",\" . join ( protocols ) if origin is not None : real_headers [ hdrs . ORIGIN ] = origin if compress : extstr = ws_ext_gen ( compress = compress ) real_headers [ hdrs . SEC_WEBSOCKET_EXTENSIONS ] = extstr ssl = _merge_ssl_params ( ssl , verify_ssl , ssl_context , fingerprint ) # send request resp = await self . request ( method , url , params = params , headers = real_headers , read_until_eof = False , auth = auth , proxy = proxy , proxy_auth = proxy_auth , ssl = ssl , proxy_headers = proxy_headers , ) try : # check handshake if resp . status != 101 : raise WSServerHandshakeError ( resp . request_info , resp . history , message = \"Invalid response status\" , status = resp . status , headers = resp . headers , ) if resp . headers . get ( hdrs . UPGRADE , \"\" ) . lower () != \"websocket\" : raise WSServerHandshakeError ( resp . request_info , resp . history , message = \"Invalid upgrade header\" , status = resp . status , headers = resp . headers , ) if resp . headers . get ( hdrs . CONNECTION , \"\" ) . lower () != \"upgrade\" : raise WSServerHandshakeError ( resp . request_info , resp . history , message = \"Invalid connection header\" , status = resp . status , headers = resp . headers , ) # key calculation r_key = resp . headers . get ( hdrs . SEC_WEBSOCKET_ACCEPT , \"\" ) match = base64 . b64encode ( hashlib . sha1 ( sec_key + WS_KEY ) . digest ()) . decode () if r_key != match : raise WSServerHandshakeError ( resp . request_info , resp . history , message = \"Invalid challenge response\" , status = resp . status , headers = resp . headers , ) # websocket protocol protocol = None if protocols and hdrs . SEC_WEBSOCKET_PROTOCOL in resp . headers : resp_protocols = [ proto . strip () for proto in resp . headers [ hdrs . SEC_WEBSOCKET_PROTOCOL ] . split ( \",\" ) ] for proto in resp_protocols : if proto in protocols : protocol = proto break # websocket compress notakeover = False if compress : compress_hdrs = resp . headers . get ( hdrs . SEC_WEBSOCKET_EXTENSIONS ) if compress_hdrs : try : compress , notakeover = ws_ext_parse ( compress_hdrs ) except WSHandshakeError as exc : raise WSServerHandshakeError ( resp . request_info , resp . history , message = exc . args [ 0 ], status = resp . status , headers = resp . headers , ) from exc else : compress = 0 notakeover = False conn = resp . connection assert conn is not None conn_proto = conn . protocol assert conn_proto is not None transport = conn . transport assert transport is not None reader : FlowControlDataQueue [ WSMessage ] = FlowControlDataQueue ( conn_proto , 2 ** 16 , loop = self . _loop ) conn_proto . set_parser ( WebSocketReader ( reader , max_msg_size ), reader ) writer = WebSocketWriter ( conn_proto , transport , use_mask = True , compress = compress , notakeover = notakeover , ) except BaseException : resp . close () raise else : return self . _ws_response_class ( reader , writer , protocol , resp , timeout , autoclose , autoping , self . _loop , receive_timeout = receive_timeout , heartbeat = heartbeat , compress = compress , client_notakeover = notakeover , ) def _prepare_headers ( self , headers : Optional [ LooseHeaders ]) -> \"CIMultiDict[str]\" : \"\"\"Add default headers and transform it to CIMultiDict\"\"\" # Convert headers to MultiDict result = CIMultiDict ( self . _default_headers ) if headers : if not isinstance ( headers , ( MultiDictProxy , MultiDict )): headers = CIMultiDict ( headers ) added_names : Set [ str ] = set () for key , value in headers . items (): if key in added_names : result . add ( key , value ) else : result [ key ] = value added_names . add ( key ) return result def get ( self , url : StrOrURL , * , allow_redirects : bool = True , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP GET request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_GET , url , allow_redirects = allow_redirects , ** kwargs ) ) def options ( self , url : StrOrURL , * , allow_redirects : bool = True , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP OPTIONS request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_OPTIONS , url , allow_redirects = allow_redirects , ** kwargs ) ) def head ( self , url : StrOrURL , * , allow_redirects : bool = False , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP HEAD request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_HEAD , url , allow_redirects = allow_redirects , ** kwargs ) ) def post ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP POST request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_POST , url , data = data , ** kwargs ) ) def put ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP PUT request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_PUT , url , data = data , ** kwargs ) ) def patch ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP PATCH request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_PATCH , url , data = data , ** kwargs ) ) def delete ( self , url : StrOrURL , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP DELETE request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_DELETE , url , ** kwargs )) async def close ( self ) -> None : \"\"\"Close underlying connector. Release all acquired resources. \"\"\" if not self . closed : if self . _connector is not None and self . _connector_owner : await self . _connector . close () self . _connector = None @property def closed ( self ) -> bool : \"\"\"Is client session closed. A readonly property. \"\"\" return self . _connector is None or self . _connector . closed @property def connector ( self ) -> Optional [ BaseConnector ]: \"\"\"Connector instance used for the session.\"\"\" return self . _connector @property def cookie_jar ( self ) -> AbstractCookieJar : \"\"\"The session cookies.\"\"\" return self . _cookie_jar @property def version ( self ) -> Tuple [ int , int ]: \"\"\"The session HTTP protocol version.\"\"\" return self . _version @property def requote_redirect_url ( self ) -> bool : \"\"\"Do URL requoting on redirection handling.\"\"\" return self . _requote_redirect_url @requote_redirect_url . setter def requote_redirect_url ( self , val : bool ) -> None : \"\"\"Do URL requoting on redirection handling.\"\"\" warnings . warn ( \"session.requote_redirect_url modification \" \"is deprecated #2778\" , DeprecationWarning , stacklevel = 2 , ) self . _requote_redirect_url = val @property def loop ( self ) -> asyncio . AbstractEventLoop : \"\"\"Session's loop.\"\"\" warnings . warn ( \"client.loop property is deprecated\" , DeprecationWarning , stacklevel = 2 ) return self . _loop @property def timeout ( self ) -> ClientTimeout : \"\"\"Timeout for the session.\"\"\" return self . _timeout @property def headers ( self ) -> \"CIMultiDict[str]\" : \"\"\"The default headers of the client session.\"\"\" return self . _default_headers @property def skip_auto_headers ( self ) -> FrozenSet [ istr ]: \"\"\"Headers for which autogeneration should be skipped\"\"\" return self . _skip_auto_headers @property def auth ( self ) -> Optional [ BasicAuth ]: \"\"\"An object that represents HTTP Basic Authorization\"\"\" return self . _default_auth @property def json_serialize ( self ) -> JSONEncoder : \"\"\"Json serializer callable\"\"\" return self . _json_serialize @property def connector_owner ( self ) -> bool : \"\"\"Should connector be closed on session closing\"\"\" return self . _connector_owner @property def raise_for_status ( self , ) -> Union [ bool , Callable [[ ClientResponse ], Awaitable [ None ]]]: \"\"\"Should `ClientResponse.raise_for_status()` be called for each response.\"\"\" return self . _raise_for_status @property def auto_decompress ( self ) -> bool : \"\"\"Should the body response be automatically decompressed.\"\"\" return self . _auto_decompress @property def trust_env ( self ) -> bool : \"\"\" Should proxies information from environment or netrc be trusted. Information is from HTTP_PROXY / HTTPS_PROXY environment variables or ~/.netrc file if present. \"\"\" return self . _trust_env @property def trace_configs ( self ) -> List [ TraceConfig ]: \"\"\"A list of TraceConfig instances used for client tracing\"\"\" return self . _trace_configs def detach ( self ) -> None : \"\"\"Detach connector from session without closing the former. Session is switched to closed state anyway. \"\"\" self . _connector = None def __enter__ ( self ) -> None : raise TypeError ( \"Use async with instead\" ) def __exit__ ( self , exc_type : Optional [ Type [ BaseException ]], exc_val : Optional [ BaseException ], exc_tb : Optional [ TracebackType ], ) -> None : # __exit__ should exist in pair with __enter__ but never executed pass # pragma: no cover async def __aenter__ ( self ) -> \"ClientSession\" : return self async def __aexit__ ( self , exc_type : Optional [ Type [ BaseException ]], exc_val : Optional [ BaseException ], exc_tb : Optional [ TracebackType ], ) -> None : await self . close () closed : bool property readonly Is client session closed. A readonly property. connector : Optional [ aiohttp . connector . BaseConnector ] property readonly Connector instance used for the session. cookie_jar : AbstractCookieJar property readonly The session cookies. headers : CIMultiDict [ str ] property readonly The default headers of the client session. timeout : ClientTimeout property readonly Timeout for the session. close ( self ) async Close underlying connector. Release all acquired resources. Source code in aiotest\\client.py async def close ( self ) -> None : \"\"\"Close underlying connector. Release all acquired resources. \"\"\" if not self . closed : if self . _connector is not None and self . _connector_owner : await self . _connector . close () self . _connector = None delete ( self , url , ** kwargs ) Perform HTTP DELETE request. Source code in aiotest\\client.py def delete ( self , url : StrOrURL , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP DELETE request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_DELETE , url , ** kwargs )) detach ( self ) Detach connector from session without closing the former. Session is switched to closed state anyway. Source code in aiotest\\client.py def detach ( self ) -> None : \"\"\"Detach connector from session without closing the former. Session is switched to closed state anyway. \"\"\" self . _connector = None get ( self , url , * , allow_redirects = True , ** kwargs ) Perform HTTP GET request. Source code in aiotest\\client.py def get ( self , url : StrOrURL , * , allow_redirects : bool = True , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP GET request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_GET , url , allow_redirects = allow_redirects , ** kwargs ) ) head ( self , url , * , allow_redirects = False , ** kwargs ) Perform HTTP HEAD request. Source code in aiotest\\client.py def head ( self , url : StrOrURL , * , allow_redirects : bool = False , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP HEAD request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_HEAD , url , allow_redirects = allow_redirects , ** kwargs ) ) options ( self , url , * , allow_redirects = True , ** kwargs ) Perform HTTP OPTIONS request. Source code in aiotest\\client.py def options ( self , url : StrOrURL , * , allow_redirects : bool = True , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP OPTIONS request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_OPTIONS , url , allow_redirects = allow_redirects , ** kwargs ) ) patch ( self , url , * , data = None , ** kwargs ) Perform HTTP PATCH request. Source code in aiotest\\client.py def patch ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP PATCH request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_PATCH , url , data = data , ** kwargs ) ) post ( self , url , * , data = None , ** kwargs ) Perform HTTP POST request. Source code in aiotest\\client.py def post ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP POST request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_POST , url , data = data , ** kwargs ) ) put ( self , url , * , data = None , ** kwargs ) Perform HTTP PUT request. Source code in aiotest\\client.py def put ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP PUT request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_PUT , url , data = data , ** kwargs ) ) request ( self , method , url , ** kwargs ) Perform HTTP request. Source code in aiotest\\client.py def request ( self , method : str , url : StrOrURL , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP request.\"\"\" return _RequestContextManager ( self . _request ( method , url , ** kwargs )) LoadUserShape class A simple load test shape class used to control the shape of load generated during a load test. Source code in aiotest\\shape.py class LoadUserShape ( metaclass = ABCMeta ): \"\"\" A simple load test shape class used to control the shape of load generated during a load test. \"\"\" def __init__ ( self ): self . start_time = default_timer () def reset_time ( self ): \"Resets start time back to 0\" self . start_time = default_timer () def get_run_time ( self ): \"Calculates run time in seconds of the load user\" return default_timer () - self . start_time @abstractmethod def tick ( self ): \"\"\" Returns a tuple with 2 elements to control the running load user: user_count -- Total user count rate -- Number of users to start/stop per second when changing number of users if 'None' is returned then the running load user will be stopped. \"\"\" return None get_run_time ( self ) Calculates run time in seconds of the load user Source code in aiotest\\shape.py def get_run_time ( self ): \"Calculates run time in seconds of the load user\" return default_timer () - self . start_time reset_time ( self ) Resets start time back to 0 Source code in aiotest\\shape.py def reset_time ( self ): \"Resets start time back to 0\" self . start_time = default_timer () tick ( self ) Returns a tuple with 2 elements to control the running load user: user_count -- Total user count rate -- Number of users to start/stop per second when changing number of users if 'None' is returned then the running load user will be stopped. Source code in aiotest\\shape.py @abstractmethod def tick ( self ): \"\"\" Returns a tuple with 2 elements to control the running load user: user_count -- Total user count rate -- Number of users to start/stop per second when changing number of users if 'None' is returned then the running load user will be stopped. \"\"\" return None Runner class Source code in aiotest\\runners.py class Runner : def __init__ ( self , user_classes , shape_class , options ): self . user_classes = user_classes self . shape_class = shape_class self . options = options self . cpu_usage = 0 self . state = STATE_INIT self . user_instances = [] self . tasks = [] self . is_quit = False def __del__ ( self ): for task in self . tasks : if not task . done (): task . cancel () @property def user_count ( self ): \"Returns the number of running user tasks, a user equals a task\" return len ([ instances for instances in self . user_instances if not instances . task . done ()]) def update_state ( self , new_state ): logger . debug ( f \"Updating state to { new_state } , old state was { self . state } \" ) self . state = new_state def weight_users ( self , amount ): \"\"\" Distributes the amount of users for each User-class according to it's weight returns a list \"bucket\" with the weighted users \"\"\" weight_sum = 0 for user in self . user_classes : if self . options . host : user . host = self . options . host try : if isinstance ( user . weight , int ) and user . weight >= 1 : weight_sum += user . weight else : raise ValueError ( \"weigth value must be an int type and >= 1\" ) except KeyError : raise KeyError ( \"Userclass must have weight attribute\" ) residuals = {} bucket = [] for user in self . user_classes : # create users depending on weight percent = user . weight / weight_sum num_users = round ( amount * percent ) residuals [ user ] = amount * percent - num_users bucket . extend ([ user for i in range ( num_users )]) if len ( bucket ) < amount : for user in [ l for l , r in sorted ( residuals . items (), key = lambda x : x [ 1 ], reverse = True )][: amount - len ( bucket )]: bucket . append ( user ) elif len ( bucket ) > amount : for user in [ l for l , r in sorted ( residuals . items (), key = lambda x : x [ 1 ])][: len ( bucket ) - amount ]: bucket . remove ( user ) # [<class 'User01'>, <class 'User02'>,...] return bucket async def start ( self , user_count , rate ): \"Create user tasks for a load test master entry\" if not isinstance ( user_count , int ) or user_count <= 0 : logger . warning ( f \" { user_count } mast be int type and >= 1\" ) sys . exit ( 1 ) if rate <= 0 or rate > user_count : logger . warning ( f \" { rate } mast > 0 and < user_count { user_count } \" ) sys . exit ( 1 ) if rate % 1 != 0 : logger . warning ( f \" { rate } rate fractional part is't 0\" ) # Dynamically changing the user count if self . state in [ STATE_STARTING , STATE_RUNNING ]: logger . debug ( f \"Updating running test with { user_count } users, { rate : .2f } rate.\" ) self . update_state ( STATE_STARTING ) if self . user_count > user_count : # stop some users stop_count = self . user_count - user_count await self . stop_users ( stop_count , rate ) self . update_state ( STATE_RUNNING ) elif self . user_count < user_count : # start some users start_count = user_count - self . user_count await self . start_users ( start_count , rate ) self . update_state ( STATE_RUNNING ) else : self . update_state ( STATE_RUNNING ) elif self . state == STATE_INIT : await self . start_users ( user_count , rate ) self . update_state ( STATE_RUNNING ) await events . start_complete . fire ( user_count = self . user_count , runner = self ) else : logger . error ( f \"runner state is { self . state } \" ) sys . exit ( 1 ) async def start_users ( self , user_count , rate ): \"Create a specified number of user tasks, a user equals a task\" bucket = self . weight_users ( user_count ) # [<class 'User01'>, <class 'User02'>,...] if self . state == STATE_INIT : self . update_state ( STATE_STARTING ) existing_count = self . user_count logger . info ( f \"starting { len ( bucket ) } users at the rate { rate } users/s, ( { existing_count } users already running)...\" ) start_count = dict (( u . __name__ , 0 ) for u in self . user_classes ) # {'User01': 0, 'User02': 0...} sleep_time = 1 / rate for i in range ( len ( bucket )): user_class = bucket . pop () start_count [ user_class . __name__ ] += 1 new_user = user_class () new_user . start_user () self . user_instances . append ( new_user ) await asyncio . sleep ( sleep_time ) if self . user_count % 10 == 0 : logger . debug ( f \" { self . user_count } users started\" ) if not bucket : logger . info ( f \"All users started: { ', ' . join ([ f ' { name } : { count } ' for name , count in start_count . items ()]) } \" ) else : logger . error ( f \" { bucket } have user_class don't started\" ) sys . exit ( 1 ) async def stop_users ( self , user_count , rate ): \"Cancels a specified number of user tasks\" bucket = self . weight_users ( user_count ) # [<class 'User01'>, <class 'User02'>,...] user_count = len ( bucket ) stop_users = [] for instances in self . user_instances : if not instances . task . done (): for user_class in bucket : if isinstance ( instances , user_class ): stop_users . append ( instances ) bucket . remove ( user_class ) break if rate >= user_count : sleep_time = 0 logger . info ( f \"Stopping { user_count } users immediately\" ) else : sleep_time = 1 / rate logger . info ( f \"Stoping { user_count } users at rate of { rate } users/s\" ) for instances in stop_users : await instances . stop_user () await asyncio . sleep ( sleep_time ) self . user_instances = [ instances for instances in self . user_instances if not instances . task . done ()] stop_users = [ instances for instances in stop_users if not instances . task . done ()] if stop_users : logger . warning ( f \"There are still user tasks uncancelled: { len ( stop_users ) } \" ) async def stop ( self ): \"Cancel all user tasks\" logger . debug ( \"Stopping all users\" ) await self . stop_users ( self . user_count , self . user_count ) await asyncio . sleep ( 0.5 ) logger . debug ( f \"all user task is done: { all ([ instances . task . done () for instances in self . user_instances ]) } \" ) for task in self . tasks : if task . get_name () == \"users_tasks\" and not task . done (): task . cancel () self . tasks . remove ( task ) break self . update_state ( STATE_STOPPED ) async def quit ( self ): \"Exit the load test and cancel all runner tasks\" if not self . is_quit : self . is_quit = True await self . stop () await asyncio . sleep ( 0.5 ) await events . quitting . fire () for task in self . tasks : if not task . done () and task != asyncio . current_task (): task . cancel () await asyncio . sleep ( 0.1 ) self . tasks = [ task for task in self . tasks if not task . done ()] logger . debug ( f \"runner's tasks is done: { len ( self . tasks ) == 1 } \" ) def start_shape ( self ): \"Create a load test policy task\" shape_task = asyncio . create_task ( self . shape_run (), name = \"shape_task\" ) self . tasks . append ( shape_task ) async def shape_run ( self ): \"Execute the specified load test policy\" logger . info ( \"Shape starting\" ) shape_last = None while True : shape_new = self . shape_class . tick () if shape_new is None : logger . info ( \"Shape test stopping\" ) await self . quit () return elif shape_last == shape_new : await asyncio . sleep ( 1 ) else : logger . debug ( shape_new ) user_count , rate = shape_new logger . info ( f \"Shape test updating to { user_count } users at { rate } rate\" ) await self . start ( user_count = user_count , rate = rate ) shape_last = shape_new user_count property readonly Returns the number of running user tasks, a user equals a task quit ( self ) async Exit the load test and cancel all runner tasks Source code in aiotest\\runners.py async def quit ( self ): \"Exit the load test and cancel all runner tasks\" if not self . is_quit : self . is_quit = True await self . stop () await asyncio . sleep ( 0.5 ) await events . quitting . fire () for task in self . tasks : if not task . done () and task != asyncio . current_task (): task . cancel () await asyncio . sleep ( 0.1 ) self . tasks = [ task for task in self . tasks if not task . done ()] logger . debug ( f \"runner's tasks is done: { len ( self . tasks ) == 1 } \" ) shape_run ( self ) async Execute the specified load test policy Source code in aiotest\\runners.py async def shape_run ( self ): \"Execute the specified load test policy\" logger . info ( \"Shape starting\" ) shape_last = None while True : shape_new = self . shape_class . tick () if shape_new is None : logger . info ( \"Shape test stopping\" ) await self . quit () return elif shape_last == shape_new : await asyncio . sleep ( 1 ) else : logger . debug ( shape_new ) user_count , rate = shape_new logger . info ( f \"Shape test updating to { user_count } users at { rate } rate\" ) await self . start ( user_count = user_count , rate = rate ) shape_last = shape_new start ( self , user_count , rate ) async Create user tasks for a load test master entry Source code in aiotest\\runners.py async def start ( self , user_count , rate ): \"Create user tasks for a load test master entry\" if not isinstance ( user_count , int ) or user_count <= 0 : logger . warning ( f \" { user_count } mast be int type and >= 1\" ) sys . exit ( 1 ) if rate <= 0 or rate > user_count : logger . warning ( f \" { rate } mast > 0 and < user_count { user_count } \" ) sys . exit ( 1 ) if rate % 1 != 0 : logger . warning ( f \" { rate } rate fractional part is't 0\" ) # Dynamically changing the user count if self . state in [ STATE_STARTING , STATE_RUNNING ]: logger . debug ( f \"Updating running test with { user_count } users, { rate : .2f } rate.\" ) self . update_state ( STATE_STARTING ) if self . user_count > user_count : # stop some users stop_count = self . user_count - user_count await self . stop_users ( stop_count , rate ) self . update_state ( STATE_RUNNING ) elif self . user_count < user_count : # start some users start_count = user_count - self . user_count await self . start_users ( start_count , rate ) self . update_state ( STATE_RUNNING ) else : self . update_state ( STATE_RUNNING ) elif self . state == STATE_INIT : await self . start_users ( user_count , rate ) self . update_state ( STATE_RUNNING ) await events . start_complete . fire ( user_count = self . user_count , runner = self ) else : logger . error ( f \"runner state is { self . state } \" ) sys . exit ( 1 ) start_shape ( self ) Create a load test policy task Source code in aiotest\\runners.py def start_shape ( self ): \"Create a load test policy task\" shape_task = asyncio . create_task ( self . shape_run (), name = \"shape_task\" ) self . tasks . append ( shape_task ) start_users ( self , user_count , rate ) async Create a specified number of user tasks, a user equals a task Source code in aiotest\\runners.py async def start_users ( self , user_count , rate ): \"Create a specified number of user tasks, a user equals a task\" bucket = self . weight_users ( user_count ) # [<class 'User01'>, <class 'User02'>,...] if self . state == STATE_INIT : self . update_state ( STATE_STARTING ) existing_count = self . user_count logger . info ( f \"starting { len ( bucket ) } users at the rate { rate } users/s, ( { existing_count } users already running)...\" ) start_count = dict (( u . __name__ , 0 ) for u in self . user_classes ) # {'User01': 0, 'User02': 0...} sleep_time = 1 / rate for i in range ( len ( bucket )): user_class = bucket . pop () start_count [ user_class . __name__ ] += 1 new_user = user_class () new_user . start_user () self . user_instances . append ( new_user ) await asyncio . sleep ( sleep_time ) if self . user_count % 10 == 0 : logger . debug ( f \" { self . user_count } users started\" ) if not bucket : logger . info ( f \"All users started: { ', ' . join ([ f ' { name } : { count } ' for name , count in start_count . items ()]) } \" ) else : logger . error ( f \" { bucket } have user_class don't started\" ) sys . exit ( 1 ) stop ( self ) async Cancel all user tasks Source code in aiotest\\runners.py async def stop ( self ): \"Cancel all user tasks\" logger . debug ( \"Stopping all users\" ) await self . stop_users ( self . user_count , self . user_count ) await asyncio . sleep ( 0.5 ) logger . debug ( f \"all user task is done: { all ([ instances . task . done () for instances in self . user_instances ]) } \" ) for task in self . tasks : if task . get_name () == \"users_tasks\" and not task . done (): task . cancel () self . tasks . remove ( task ) break self . update_state ( STATE_STOPPED ) stop_users ( self , user_count , rate ) async Cancels a specified number of user tasks Source code in aiotest\\runners.py async def stop_users ( self , user_count , rate ): \"Cancels a specified number of user tasks\" bucket = self . weight_users ( user_count ) # [<class 'User01'>, <class 'User02'>,...] user_count = len ( bucket ) stop_users = [] for instances in self . user_instances : if not instances . task . done (): for user_class in bucket : if isinstance ( instances , user_class ): stop_users . append ( instances ) bucket . remove ( user_class ) break if rate >= user_count : sleep_time = 0 logger . info ( f \"Stopping { user_count } users immediately\" ) else : sleep_time = 1 / rate logger . info ( f \"Stoping { user_count } users at rate of { rate } users/s\" ) for instances in stop_users : await instances . stop_user () await asyncio . sleep ( sleep_time ) self . user_instances = [ instances for instances in self . user_instances if not instances . task . done ()] stop_users = [ instances for instances in stop_users if not instances . task . done ()] if stop_users : logger . warning ( f \"There are still user tasks uncancelled: { len ( stop_users ) } \" ) weight_users ( self , amount ) Distributes the amount of users for each User-class according to it's weight returns a list \"bucket\" with the weighted users Source code in aiotest\\runners.py def weight_users ( self , amount ): \"\"\" Distributes the amount of users for each User-class according to it's weight returns a list \"bucket\" with the weighted users \"\"\" weight_sum = 0 for user in self . user_classes : if self . options . host : user . host = self . options . host try : if isinstance ( user . weight , int ) and user . weight >= 1 : weight_sum += user . weight else : raise ValueError ( \"weigth value must be an int type and >= 1\" ) except KeyError : raise KeyError ( \"Userclass must have weight attribute\" ) residuals = {} bucket = [] for user in self . user_classes : # create users depending on weight percent = user . weight / weight_sum num_users = round ( amount * percent ) residuals [ user ] = amount * percent - num_users bucket . extend ([ user for i in range ( num_users )]) if len ( bucket ) < amount : for user in [ l for l , r in sorted ( residuals . items (), key = lambda x : x [ 1 ], reverse = True )][: amount - len ( bucket )]: bucket . append ( user ) elif len ( bucket ) > amount : for user in [ l for l , r in sorted ( residuals . items (), key = lambda x : x [ 1 ])][: len ( bucket ) - amount ]: bucket . remove ( user ) # [<class 'User01'>, <class 'User02'>,...] return bucket LocalRunner class Source code in aiotest\\runners.py class LocalRunner ( Runner ): def __init__ ( self , user_classes , shape_class , options ): super () . __init__ ( user_classes , shape_class , options ) user_count_task = asyncio . create_task ( exporter_user_count ( self ), name = \"user_count_task\" ) prometheus_task = asyncio . create_task ( prometheus_server ( self . options . prometheus_port ), name = \"prometheus\" ) monitor_cpu_task = asyncio . create_task ( exporter_cpu_usage ( self ), name = \"monitor_cpu\" ) self . tasks . append ( user_count_task ) self . tasks . append ( prometheus_task ) self . tasks . append ( monitor_cpu_task ) async def start ( self , user_count , rate ): if rate > 100 : logger . warning ( \"Your selected rate is very high (>100), and this is known to sometimes cause issues. Do you really need to ramp up that fast?\" ) if self . state == STATE_INIT : await events . test_start . fire ( runner = self ) for task in asyncio . all_tasks (): if task . get_name () == \"users_tasks\" and not task . done (): # cancel existing task(name='users_tasks') before we start a new one task . cancel () break users_tasks = asyncio . create_task ( super () . start ( user_count , rate ), name = \"users_tasks\" ) self . tasks . append ( users_tasks ) async def stop ( self ): # if self.state == STATE_STOPPED: # return await super () . stop () await events . test_stop . fire ( runner = self ) start ( self , user_count , rate ) async Create user tasks for a load test master entry Source code in aiotest\\runners.py async def start ( self , user_count , rate ): if rate > 100 : logger . warning ( \"Your selected rate is very high (>100), and this is known to sometimes cause issues. Do you really need to ramp up that fast?\" ) if self . state == STATE_INIT : await events . test_start . fire ( runner = self ) for task in asyncio . all_tasks (): if task . get_name () == \"users_tasks\" and not task . done (): # cancel existing task(name='users_tasks') before we start a new one task . cancel () break users_tasks = asyncio . create_task ( super () . start ( user_count , rate ), name = \"users_tasks\" ) self . tasks . append ( users_tasks ) stop ( self ) async Cancel all user tasks Source code in aiotest\\runners.py async def stop ( self ): # if self.state == STATE_STOPPED: # return await super () . stop () await events . test_stop . fire ( runner = self ) MasterRunner class Runner used to run distributed load tests across multiple processes and/or machines. Source code in aiotest\\runners.py class MasterRunner ( DistributedRunner ): \"\"\" Runner used to run distributed load tests across multiple processes and/or machines. \"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) class WorkerNodesDict ( dict ): def get_by_state ( self , state ): return [ c for c in self . values () if c . state == state ] @property def all ( self ): return self . values () @property def ready ( self ): return self . get_by_state ( STATE_INIT ) @property def starting ( self ): return self . get_by_state ( STATE_STARTING ) @property def running ( self ): return self . get_by_state ( STATE_RUNNING ) @property def missing ( self ): return self . get_by_state ( STATE_MISSING ) self . workers = WorkerNodesDict () self . server = Server ( self . master_bind_host , self . master_bind_port ) worekr_heartbeat_task = asyncio . create_task ( self . worker_heartbeat (), name = \"worekr_heartbeat\" ) worekr_listener_task = asyncio . create_task ( self . worekr_listener (), name = \"worekr_listener\" ) prometheus_task = asyncio . create_task ( prometheus_server ( self . options . prometheus_port ), name = \"prometheus\" ) monitor_cpu_task = asyncio . create_task ( exporter_cpu_usage ( self ), name = \"monitor_cpu\" ) self . tasks . append ( worekr_heartbeat_task ) self . tasks . append ( worekr_listener_task ) self . tasks . append ( prometheus_task ) self . tasks . append ( monitor_cpu_task ) @property def user_count ( self ): return sum ([ c . user_count for c in self . workers . values ()]) @property def worker_count ( self ): return len ( self . workers . ready ) + len ( self . workers . starting ) + len ( self . workers . running ) async def start ( self , user_count , rate ): num_workers = self . worker_count if not num_workers : logger . warning ( \"You are running in distributed mode but have no worker servers connected. Please connect workers prior to swarming.\" ) return worker_host = self . options . host worker_user_count = user_count // ( num_workers or 1 ) # \u6bcf\u4e2aworker\u5206\u914duser_count worker_rate = rate / ( num_workers or 1 ) # \u6bcf\u4e2aworker\u751f\u6210user\u901f\u7387 remainig = user_count % num_workers # \u5269\u4e0b\u7684user_count logger . info ( f \"Sending jobs of { worker_user_count } users and { worker_rate : .2f } rate to { num_workers } ready workers\" ) if worker_rate > 100 : logger . warning ( \"Your selected rate is very high (>100/worker), and this is known to sometimes cause issues. Do you really need to ramp up that fast?\" ) if self . state == STATE_INIT : await events . test_start . fire ( runner = self ) self . update_state ( STATE_STARTING ) for worker in ( self . workers . ready + self . workers . starting + self . workers . running ): data = { \"user_count\" : worker_user_count , \"rate\" : worker_rate , \"host\" : worker_host } if remainig > 0 : data [ \"user_count\" ] += 1 remainig -= 1 logger . debug ( f \"Sending start users message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"start\" , data , worker . id )) async def stop ( self ): logger . debug ( \"Stopping...\" ) # \u907f\u514d\u76f4\u5230tick\uff08\uff09\u53d1\u51fa\u53e6\u4e00\u4e2a\u53d8\u5316\u4fe1\u53f7\u65f6\u624d\u505c\u6b62 if self . shape_class : self . tactics_current = None for worker in self . workers . all : logger . debug ( f \"Sending stop message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"stop\" , None , worker . id )) await events . test_stop . fire ( runner = self ) self . update_state ( STATE_STOPPED ) async def quit ( self ): logger . debug ( \"Quitting...\" ) if not self . is_quit : self . is_quit = True await self . stop () await asyncio . sleep ( 0.5 ) for worker in self . workers . all : logger . debug ( f \"Sending quit message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"quit\" , None , worker . id )) await asyncio . sleep ( 0.5 ) # wait for final stats report from all workers await events . quitting . fire () for task in self . tasks : if not task . done (): task . cancel () self . server . close () async def worker_heartbeat ( self ): while True : await asyncio . sleep ( HEARTBEAT_INTERVAL ) if self . connection_broken : await self . reset_connection () continue for worker in self . workers . all : if worker . heartbeat < 0 and worker . state != STATE_MISSING : logger . warning ( f \"Worker { worker . id } failed to send heartbeat, setting state to missing.\" ) worker . state = STATE_MISSING worker . user_count = 0 if self . worker_count - len ( self . workers . missing ) <= 0 : logger . warning ( \"The last worker went missing, stopping test.\" ) await self . stop () else : worker . heartbeat -= 1 async def reset_connection ( self ): logger . info ( \"Reset connection to worker\" ) try : self . server . close () self . server = Server ( self . master_bind_host , self . master_bind_port ) except RPCError as e : logger . error ( f \"Temporary failure when resetting connection: { e } , will retry later.\" ) async def worekr_listener ( self ): while True : try : worker_id , msg = await self . server . recv_from_worker () msg . node_id = worker_id except RPCError as e : logger . error ( f \"RPCError found when receiving from worker: { e } \" ) self . connection_broken = True await asyncio . sleep ( FALLBACK_INTERVAL ) continue self . connection_broken = False if msg . type == \"heartbeat\" : if worker_id in self . workers : c = self . workers [ worker_id ] c . heartbeat = HEARTBEAT_LIVENESS c . state = msg . data [ \"state\" ] c . cpu_usage = msg . data [ \"cpu_usage\" ] if c . cpu_usage >= 90 : logger . warning ( f \"Worker { worker_id } exceeded CPU threshold\" ) elif msg . type == \"stats\" : if worker_id not in self . workers : logger . warning ( f \"Discarded report from unrecognized worker { worker_id } \" ) else : self . workers [ worker_id ] . user_count = msg . data [ \"user_count\" ] await events . worker_report . fire ( runner = self , worker_id = worker_id , data = msg . data ) elif msg . type == \"error\" : await events . user_error . fire ( runner = self , error = msg . data [ \"error\" ]) elif msg . type == \"ready\" : self . workers [ worker_id ] = WorkerNode ( id = worker_id ) logger . info ( f \"Worker { worker_id } reported as ready. Currently { self . worker_count } workers ready to swarm.\" ) if self . state in [ STATE_STARTING , STATE_RUNNING ]: # balance the load distribution when new worker joins self . start ( self . options . user_count , self . options . rate ) elif msg . type == \"starting\" : self . workers [ worker_id ] . state = STATE_STARTING elif msg . type == \"start_complete\" : self . workers [ worker_id ] . state = STATE_RUNNING self . workers [ worker_id ] . user_count = msg . data [ \"user_count\" ] if len ( self . workers . running ) == len ( self . workers . all ): self . update_state ( STATE_RUNNING ) await events . start_complete . fire ( user_count = self . user_count , runner = self ) elif msg . type == \"stopped\" : if worker_id in self . workers : del self . workers [ worker_id ] logger . info ( f \"Removing { worker_id } worker from running workers\" ) elif msg . type == \"quitted\" : if worker_id in self . workers : del self . workers [ worker_id ] logger . info ( f \"Worker { worker_id } quitted. Currently { self . worker_count } workers connected.\" ) user_count property readonly Returns the number of running user tasks, a user equals a task quit ( self ) async Exit the load test and cancel all runner tasks Source code in aiotest\\runners.py async def quit ( self ): logger . debug ( \"Quitting...\" ) if not self . is_quit : self . is_quit = True await self . stop () await asyncio . sleep ( 0.5 ) for worker in self . workers . all : logger . debug ( f \"Sending quit message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"quit\" , None , worker . id )) await asyncio . sleep ( 0.5 ) # wait for final stats report from all workers await events . quitting . fire () for task in self . tasks : if not task . done (): task . cancel () self . server . close () start ( self , user_count , rate ) async Create user tasks for a load test master entry Source code in aiotest\\runners.py async def start ( self , user_count , rate ): num_workers = self . worker_count if not num_workers : logger . warning ( \"You are running in distributed mode but have no worker servers connected. Please connect workers prior to swarming.\" ) return worker_host = self . options . host worker_user_count = user_count // ( num_workers or 1 ) # \u6bcf\u4e2aworker\u5206\u914duser_count worker_rate = rate / ( num_workers or 1 ) # \u6bcf\u4e2aworker\u751f\u6210user\u901f\u7387 remainig = user_count % num_workers # \u5269\u4e0b\u7684user_count logger . info ( f \"Sending jobs of { worker_user_count } users and { worker_rate : .2f } rate to { num_workers } ready workers\" ) if worker_rate > 100 : logger . warning ( \"Your selected rate is very high (>100/worker), and this is known to sometimes cause issues. Do you really need to ramp up that fast?\" ) if self . state == STATE_INIT : await events . test_start . fire ( runner = self ) self . update_state ( STATE_STARTING ) for worker in ( self . workers . ready + self . workers . starting + self . workers . running ): data = { \"user_count\" : worker_user_count , \"rate\" : worker_rate , \"host\" : worker_host } if remainig > 0 : data [ \"user_count\" ] += 1 remainig -= 1 logger . debug ( f \"Sending start users message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"start\" , data , worker . id )) stop ( self ) async Cancel all user tasks Source code in aiotest\\runners.py async def stop ( self ): logger . debug ( \"Stopping...\" ) # \u907f\u514d\u76f4\u5230tick\uff08\uff09\u53d1\u51fa\u53e6\u4e00\u4e2a\u53d8\u5316\u4fe1\u53f7\u65f6\u624d\u505c\u6b62 if self . shape_class : self . tactics_current = None for worker in self . workers . all : logger . debug ( f \"Sending stop message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"stop\" , None , worker . id )) await events . test_stop . fire ( runner = self ) self . update_state ( STATE_STOPPED ) WorkerRunner class Runner used to run distributed load tests across multiple processes and/or machines. Source code in aiotest\\runners.py class WorkerRunner ( DistributedRunner ): \"Runner used to run distributed load tests across multiple processes and/or machines.\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . worker_state = STATE_INIT # \u4e3b\u673aip\u5730\u5740 + \u968f\u673a\u7801 self . worker_id = socket . gethostbyname ( socket . gethostname ()) + \"_\" + uuid4 () . hex self . worker = Client ( self . master_host , self . master_port , self . worker_id ) heartbeat_task = asyncio . create_task ( self . heartbeat (), name = \"heartbeat\" ) worker_run_task = asyncio . create_task ( self . worker_run (), name = \"worker_run\" ) monitor_cpu_task = asyncio . create_task ( exporter_cpu_usage ( self ), name = \"monitor_cpu\" ) self . tasks . append ( heartbeat_task ) self . tasks . append ( worker_run_task ) self . tasks . append ( monitor_cpu_task ) events . start_complete += self . on_start_complete events . quitting += self . on_quitting async def on_start_complete ( self , user_count , runner ): await self . worker . send ( Message ( \"start_complete\" , { \"user_count\" : user_count }, self . worker_id )) self . worker_state = STATE_RUNNING async def on_quitting ( self ): await self . worker . send ( Message ( \"quitted\" , None , self . worker_id )) async def heartbeat ( self ): while True : try : await self . worker . send ( Message ( \"heartbeat\" , { \"state\" : self . worker_state , \"cpu_usage\" : self . cpu_usage }, self . worker_id ) ) except RPCError as e : logger . error ( f \"RPCError found when sending heartbeat: { e } \" ) self . reset_connection () finally : await asyncio . sleep ( HEARTBEAT_INTERVAL ) async def reset_connection ( self ): logger . info ( \"Reset connection to master\" ) try : self . worker . close () self . worker = Client ( self . master_host , self . master_port , self . worker_id ) except RPCError as e : logger . error ( f \"Temporary failure when resetting connection: { e } , will retry later.\" ) async def worker_run ( self ): await self . worker . send ( Message ( \"ready\" , None , self . worker_id )) while True : try : msg = await self . worker . recv () except RPCError as e : logger . error ( f \"RPCError found when receiving from master: { e } \" ) continue if msg . type == \"start\" : self . worker_state = STATE_STARTING await self . worker . send ( Message ( \"starting\" , None , self . worker_id )) job = msg . data self . options . host = job [ \"host\" ] for task in asyncio . all_tasks (): if task . get_name () == \"users_tasks\" and not task . done (): # cancel existing task(name='start_user') before we start a new one task . cancel () break users_tasks = asyncio . create_task ( self . start ( job [ \"user_count\" ], job [ \"rate\" ]), name = \"users_tasks\" ) self . tasks . append ( users_tasks ) elif msg . type == \"stop\" : await self . stop () await self . worker . send ( Message ( \"stopped\" , None , self . worker_id )) self . worker_state = STATE_STOPPED await self . worker . send ( Message ( \"ready\" , None , self . worker_id )) self . worker_state = STATE_INIT elif msg . type == \"quit\" : logger . info ( \"Got quit message from master, shutting down...\" ) await self . quit () break async def quit ( self ): \"Exit the load test and cancel all runner tasks\" await super () . quit () if self . worker : self . worker . close () quit ( self ) async Exit the load test and cancel all runner tasks Source code in aiotest\\runners.py async def quit ( self ): \"Exit the load test and cancel all runner tasks\" await super () . quit () if self . worker : self . worker . close () setup_logging Source code in aiotest\\log.py def setup_logging ( loglevel , logfile = None ): loglevel = loglevel . upper () logger . remove () logger . add ( sys . stderr , level = loglevel ) if logfile : logger . add ( logfile , level = loglevel , retention = \"1 days\" ) Events class Source code in aiotest\\events.py class EventHook : def __init__ ( self ): self . _handlers = [] def __iadd__ ( self , handler ): self . _handlers . append ( handler ) return self def __isub__ ( self , handler ): self . _handlers . remove ( handler ) return self async def fire ( self , ** kwargs ): for handler in self . _handlers : try : await handler ( ** kwargs ) except Exception as e : logger . error ( f \" { sys . exc_info ()[ 0 ] . __name__ } : { e } \" + \"\" . join ( traceback . format_tb ( sys . exc_info ()[ 2 ])) . strip ())","title":"Api"},{"location":"api/#api-reference","text":"","title":"API Reference"},{"location":"api/#user-class","text":"Source code in aiotest\\user.py class User ( metaclass = UserMeta ): host = None session = None wait_time = 1 weight = 1 task = None def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) async def on_start ( self ): \"\"\" Called when a User starts running. \"\"\" pass async def on_stop ( self ): \"\"\" Called when a User stops running (is canceled) \"\"\" if not self . session . closed : await self . session . close () self . session = None def start_user ( self ): self . task = asyncio . create_task ( self . start (), name = type ( self ) . __name__ ) async def stop_user ( self ): if not self . task . done (): self . task . cancel () await self . on_stop () async def start ( self ): \"\"\" Synchronization executes coroutines job from top to bottom \"\"\" try : try : await self . on_start () await asyncio . sleep ( self . wait_time ) except : await self . on_stop () raise while True : for job in self . jobs : await job ( self ) await asyncio . sleep ( self . wait_time ) except asyncio . CancelledError : await self . on_stop () raise except Exception as e : await events . user_error . fire ( runner = runners . global_runner , error = f \" { sys . exc_info ()[ 0 ] . __name__ } : { e } \" + \"\" . join ( traceback . format_tb ( sys . exc_info ()[ 2 ])) . strip ())","title":"User class"},{"location":"api/#aiotest.user.User.on_start","text":"Called when a User starts running. Source code in aiotest\\user.py async def on_start ( self ): \"\"\" Called when a User starts running. \"\"\" pass","title":"on_start()"},{"location":"api/#aiotest.user.User.on_stop","text":"Called when a User stops running (is canceled) Source code in aiotest\\user.py async def on_stop ( self ): \"\"\" Called when a User stops running (is canceled) \"\"\" if not self . session . closed : await self . session . close () self . session = None","title":"on_stop()"},{"location":"api/#aiotest.user.User.start","text":"Synchronization executes coroutines job from top to bottom Source code in aiotest\\user.py async def start ( self ): \"\"\" Synchronization executes coroutines job from top to bottom \"\"\" try : try : await self . on_start () await asyncio . sleep ( self . wait_time ) except : await self . on_stop () raise while True : for job in self . jobs : await job ( self ) await asyncio . sleep ( self . wait_time ) except asyncio . CancelledError : await self . on_stop () raise except Exception as e : await events . user_error . fire ( runner = runners . global_runner , error = f \" { sys . exc_info ()[ 0 ] . __name__ } : { e } \" + \"\" . join ( traceback . format_tb ( sys . exc_info ()[ 2 ])) . strip ())","title":"start()"},{"location":"api/#asynchttpuser-class","text":"Represents an AsyncHttp \"user\" which is to be started and attack the system that is to be load tested. Source code in aiotest\\user.py class AsyncHttpUser ( User ): \"\"\" Represents an AsyncHttp \"user\" which is to be started and attack the system that is to be load tested. \"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . session = ClientSession ( base_url = self . host )","title":"AsyncHttpUser class"},{"location":"api/#clienttimeout-class","text":"Source code in aiotest\\client.py @attr . s ( auto_attribs = True , frozen = True , slots = True ) class ClientTimeout : total : Optional [ float ] = None connect : Optional [ float ] = None sock_read : Optional [ float ] = None sock_connect : Optional [ float ] = None # pool_queue_timeout: Optional[float] = None # dns_resolution_timeout: Optional[float] = None # socket_connect_timeout: Optional[float] = None # connection_acquiring_timeout: Optional[float] = None # new_connection_timeout: Optional[float] = None # http_header_timeout: Optional[float] = None # response_body_timeout: Optional[float] = None # to create a timeout specific for a single request, either # - create a completely new one to overwrite the default # - or use http://www.attrs.org/en/stable/api.html#attr.evolve # to overwrite the defaults","title":"ClientTimeout class"},{"location":"api/#clientsession-class","text":"First-class interface for making HTTP requests. Source code in aiotest\\client.py class ClientSession : \"\"\"First-class interface for making HTTP requests.\"\"\" ATTRS = frozenset ( [ \"_base_url\" , \"_source_traceback\" , \"_connector\" , \"requote_redirect_url\" , \"_loop\" , \"_cookie_jar\" , \"_connector_owner\" , \"_default_auth\" , \"_version\" , \"_json_serialize\" , \"_requote_redirect_url\" , \"_timeout\" , \"_raise_for_status\" , \"_auto_decompress\" , \"_trust_env\" , \"_default_headers\" , \"_skip_auto_headers\" , \"_request_class\" , \"_response_class\" , \"_ws_response_class\" , \"_trace_configs\" , \"_read_bufsize\" , ] ) _source_traceback = None # type: Optional[traceback.StackSummary] _connector = None # type: Optional[BaseConnector] def __init__ ( self , base_url : Optional [ StrOrURL ] = None , * , connector : Optional [ BaseConnector ] = None , loop : Optional [ asyncio . AbstractEventLoop ] = None , cookies : Optional [ LooseCookies ] = None , headers : Optional [ LooseHeaders ] = None , skip_auto_headers : Optional [ Iterable [ str ]] = None , auth : Optional [ BasicAuth ] = None , json_serialize : JSONEncoder = json . dumps , request_class : Type [ ClientRequest ] = ClientRequest , response_class : Type [ ClientResponse ] = ClientResponse , ws_response_class : Type [ ClientWebSocketResponse ] = ClientWebSocketResponse , version : HttpVersion = http . HttpVersion11 , cookie_jar : Optional [ AbstractCookieJar ] = None , connector_owner : bool = True , raise_for_status : bool = False , read_timeout : Union [ float , object ] = sentinel , conn_timeout : Optional [ float ] = None , timeout : Union [ object , ClientTimeout ] = sentinel , auto_decompress : bool = True , trust_env : bool = False , requote_redirect_url : bool = True , trace_configs : Optional [ List [ TraceConfig ]] = None , read_bufsize : int = 2 ** 16 , ) -> None : if loop is None : if connector is not None : loop = connector . _loop loop = get_running_loop ( loop ) if base_url is None or isinstance ( base_url , URL ): self . _base_url : Optional [ URL ] = base_url else : self . _base_url = URL ( base_url ) assert ( self . _base_url . origin () == self . _base_url ), \"Only absolute URLs without path part are supported\" if connector is None : connector = TCPConnector ( loop = loop ) if connector . _loop is not loop : raise RuntimeError ( \"Session and connector has to use same event loop\" ) self . _loop = loop if loop . get_debug (): self . _source_traceback = traceback . extract_stack ( sys . _getframe ( 1 )) if cookie_jar is None : cookie_jar = CookieJar ( loop = loop ) self . _cookie_jar = cookie_jar if cookies is not None : self . _cookie_jar . update_cookies ( cookies ) self . _connector = connector self . _connector_owner = connector_owner self . _default_auth = auth self . _version = version self . _json_serialize = json_serialize if timeout is sentinel : self . _timeout = DEFAULT_TIMEOUT if read_timeout is not sentinel : warnings . warn ( \"read_timeout is deprecated, \" \"use timeout argument instead\" , DeprecationWarning , stacklevel = 2 , ) self . _timeout = attr . evolve ( self . _timeout , total = read_timeout ) if conn_timeout is not None : self . _timeout = attr . evolve ( self . _timeout , connect = conn_timeout ) warnings . warn ( \"conn_timeout is deprecated, \" \"use timeout argument instead\" , DeprecationWarning , stacklevel = 2 , ) else : self . _timeout = timeout # type: ignore[assignment] if read_timeout is not sentinel : raise ValueError ( \"read_timeout and timeout parameters \" \"conflict, please setup \" \"timeout.read\" ) if conn_timeout is not None : raise ValueError ( \"conn_timeout and timeout parameters \" \"conflict, please setup \" \"timeout.connect\" ) self . _raise_for_status = raise_for_status self . _auto_decompress = auto_decompress self . _trust_env = trust_env self . _requote_redirect_url = requote_redirect_url self . _read_bufsize = read_bufsize # Convert to list of tuples if headers : real_headers : CIMultiDict [ str ] = CIMultiDict ( headers ) else : real_headers = CIMultiDict () self . _default_headers : CIMultiDict [ str ] = real_headers if skip_auto_headers is not None : self . _skip_auto_headers = frozenset ( istr ( i ) for i in skip_auto_headers ) else : self . _skip_auto_headers = frozenset () self . _request_class = request_class self . _response_class = response_class self . _ws_response_class = ws_response_class self . _trace_configs = trace_configs or [] for trace_config in self . _trace_configs : trace_config . freeze () def __init_subclass__ ( cls : Type [ \"ClientSession\" ]) -> None : warnings . warn ( \"Inheritance class {} from ClientSession \" \"is discouraged\" . format ( cls . __name__ ), DeprecationWarning , stacklevel = 2 , ) if DEBUG : def __setattr__ ( self , name : str , val : Any ) -> None : if name not in self . ATTRS : warnings . warn ( \"Setting custom ClientSession. {} attribute \" \"is discouraged\" . format ( name ), DeprecationWarning , stacklevel = 2 , ) super () . __setattr__ ( name , val ) def __del__ ( self , _warnings : Any = warnings ) -> None : if not self . closed : if PY_36 : kwargs = { \"source\" : self } else : kwargs = {} _warnings . warn ( f \"Unclosed client session { self !r} \" , ResourceWarning , ** kwargs ) context = { \"client_session\" : self , \"message\" : \"Unclosed client session\" } if self . _source_traceback is not None : context [ \"source_traceback\" ] = self . _source_traceback self . _loop . call_exception_handler ( context ) def request ( self , method : str , url : StrOrURL , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP request.\"\"\" return _RequestContextManager ( self . _request ( method , url , ** kwargs )) def _build_url ( self , str_or_url : StrOrURL ) -> URL : url = URL ( str_or_url ) if self . _base_url is None : return url else : assert not url . is_absolute () and url . path . startswith ( \"/\" ) return self . _base_url . join ( url ) async def _request ( self , method : str , str_or_url : StrOrURL , * , name : str = None , params : Optional [ Mapping [ str , str ]] = None , data : Any = None , json : Any = None , cookies : Optional [ LooseCookies ] = None , headers : Optional [ LooseHeaders ] = None , skip_auto_headers : Optional [ Iterable [ str ]] = None , auth : Optional [ BasicAuth ] = None , allow_redirects : bool = True , max_redirects : int = 10 , compress : Optional [ str ] = None , chunked : Optional [ bool ] = None , expect100 : bool = False , raise_for_status : Optional [ bool ] = None , read_until_eof : bool = True , proxy : Optional [ StrOrURL ] = None , proxy_auth : Optional [ BasicAuth ] = None , timeout : Union [ ClientTimeout , object ] = sentinel , verify_ssl : Optional [ bool ] = None , fingerprint : Optional [ bytes ] = None , ssl_context : Optional [ SSLContext ] = None , ssl : Optional [ Union [ SSLContext , bool , Fingerprint ]] = None , proxy_headers : Optional [ LooseHeaders ] = None , trace_request_ctx : Optional [ SimpleNamespace ] = None , read_bufsize : Optional [ int ] = None , ) -> ClientResponse : # NOTE: timeout clamps existing connect and read timeouts. We cannot # set the default to None because we need to detect if the user wants # to use the existing timeouts by setting timeout to None. if self . closed : raise RuntimeError ( \"Session is closed\" ) ssl = _merge_ssl_params ( ssl , verify_ssl , ssl_context , fingerprint ) if data is not None and json is not None : raise ValueError ( \"data and json parameters can not be used at the same time\" ) elif json is not None : data = payload . JsonPayload ( json , dumps = self . _json_serialize ) if not isinstance ( chunked , bool ) and chunked is not None : warnings . warn ( \"Chunk size is deprecated #1615\" , DeprecationWarning ) redirects = 0 history = [] version = self . _version # Merge with default headers and transform to CIMultiDict headers = self . _prepare_headers ( headers ) proxy_headers = self . _prepare_headers ( proxy_headers ) try : url = self . _build_url ( str_or_url ) except ValueError as e : raise InvalidURL ( str_or_url ) from e skip_headers = set ( self . _skip_auto_headers ) if skip_auto_headers is not None : for i in skip_auto_headers : skip_headers . add ( istr ( i )) if proxy is not None : try : proxy = URL ( proxy ) except ValueError as e : raise InvalidURL ( proxy ) from e if timeout is sentinel : real_timeout : ClientTimeout = self . _timeout else : if not isinstance ( timeout , ClientTimeout ): real_timeout = ClientTimeout ( total = timeout ) # type: ignore[arg-type] else : real_timeout = timeout # timeout is cumulative for all request operations # (request, redirects, responses, data consuming) tm = TimeoutHandle ( self . _loop , real_timeout . total ) handle = tm . start () if read_bufsize is None : read_bufsize = self . _read_bufsize traces = [ Trace ( self , trace_config , trace_config . trace_config_ctx ( trace_request_ctx = trace_request_ctx ), ) for trace_config in self . _trace_configs ] for trace in traces : await trace . send_request_start ( method , url . update_query ( params ), headers ) timer = tm . timer () try : with timer : while True : url , auth_from_url = strip_auth_from_url ( url ) if auth and auth_from_url : raise ValueError ( \"Cannot combine AUTH argument with \" \"credentials encoded in URL\" ) if auth is None : auth = auth_from_url if auth is None : auth = self . _default_auth # It would be confusing if we support explicit # Authorization header with auth argument if ( headers is not None and auth is not None and hdrs . AUTHORIZATION in headers ): raise ValueError ( \"Cannot combine AUTHORIZATION header \" \"with AUTH argument or credentials \" \"encoded in URL\" ) all_cookies = self . _cookie_jar . filter_cookies ( url ) if cookies is not None : tmp_cookie_jar = CookieJar () tmp_cookie_jar . update_cookies ( cookies ) req_cookies = tmp_cookie_jar . filter_cookies ( url ) if req_cookies : all_cookies . load ( req_cookies ) if proxy is not None : proxy = URL ( proxy ) elif self . _trust_env : with suppress ( LookupError ): proxy , proxy_auth = get_env_proxy_for_url ( url ) req = self . _request_class ( method , url , params = params , headers = headers , skip_auto_headers = skip_headers , data = data , cookies = all_cookies , auth = auth , version = version , compress = compress , chunked = chunked , expect100 = expect100 , loop = self . _loop , response_class = self . _response_class , proxy = proxy , proxy_auth = proxy_auth , timer = timer , session = self , ssl = ssl , proxy_headers = proxy_headers , traces = traces , ) # Collect request data request_meta = {} request_meta [ \"request_name\" ] = name if name else url . path request_meta [ \"request_method\" ] = method # connection timeout try : async with ceil_timeout ( real_timeout . connect ): assert self . _connector is not None # requests start time request_meta [ \"start_time\" ] = default_timer () conn = await self . _connector . connect ( req , traces = traces , timeout = real_timeout ) except asyncio . TimeoutError as exc : raise ServerTimeoutError ( \"Connection timeout \" \"to host {} \" . format ( url ) ) from exc assert conn . transport is not None assert conn . protocol is not None conn . protocol . set_response_params ( timer = timer , skip_payload = method . upper () == \"HEAD\" , read_until_eof = read_until_eof , auto_decompress = self . _auto_decompress , read_timeout = real_timeout . sock_read , read_bufsize = read_bufsize , ) try : try : resp = await req . send ( conn ) try : await resp . start ( conn ) except BaseException : resp . close () raise except BaseException : conn . close () raise except ClientError : raise except OSError as exc : if exc . errno is None and isinstance ( exc , asyncio . TimeoutError ): raise raise ClientOSError ( * exc . args ) from exc self . _cookie_jar . update_cookies ( resp . cookies , resp . url ) # redirects if resp . status in ( 301 , 302 , 303 , 307 , 308 ) and allow_redirects : for trace in traces : await trace . send_request_redirect ( method , url . update_query ( params ), headers , resp ) redirects += 1 history . append ( resp ) if max_redirects and redirects >= max_redirects : resp . close () raise TooManyRedirects ( history [ 0 ] . request_info , tuple ( history ) ) # For 301 and 302, mimic IE, now changed in RFC # https://github.com/kennethreitz/requests/pull/269 if ( resp . status == 303 and resp . method != hdrs . METH_HEAD ) or ( resp . status in ( 301 , 302 ) and resp . method == hdrs . METH_POST ): method = hdrs . METH_GET data = None if headers . get ( hdrs . CONTENT_LENGTH ): headers . pop ( hdrs . CONTENT_LENGTH ) r_url = resp . headers . get ( hdrs . LOCATION ) or resp . headers . get ( hdrs . URI ) if r_url is None : # see github.com/aio-libs/aiohttp/issues/2022 break else : # reading from correct redirection # response is forbidden resp . release () try : parsed_url = URL ( r_url , encoded = not self . _requote_redirect_url ) except ValueError as e : raise InvalidURL ( r_url ) from e scheme = parsed_url . scheme if scheme not in ( \"http\" , \"https\" , \"\" ): resp . close () raise ValueError ( \"Can redirect only to http or https\" ) elif not scheme : parsed_url = url . join ( parsed_url ) if url . origin () != parsed_url . origin (): auth = None headers . pop ( hdrs . AUTHORIZATION , None ) url = parsed_url params = None resp . release () continue break # check response status if raise_for_status is None : raise_for_status = self . _raise_for_status if raise_for_status : resp . raise_for_status () # register connection if handle is not None : if resp . connection is not None : resp . connection . add_callback ( handle . cancel ) else : handle . cancel () resp . _history = tuple ( history ) for trace in traces : await trace . send_request_end ( method , url . update_query ( params ), headers , resp ) resp . request_meta = request_meta return resp except BaseException as e : # cleanup timer tm . close () if handle : handle . cancel () handle = None for trace in traces : await trace . send_request_exception ( method , url . update_query ( params ), headers , e ) raise def ws_connect ( self , url : StrOrURL , * , method : str = hdrs . METH_GET , protocols : Iterable [ str ] = (), timeout : float = 10.0 , receive_timeout : Optional [ float ] = None , autoclose : bool = True , autoping : bool = True , heartbeat : Optional [ float ] = None , auth : Optional [ BasicAuth ] = None , origin : Optional [ str ] = None , params : Optional [ Mapping [ str , str ]] = None , headers : Optional [ LooseHeaders ] = None , proxy : Optional [ StrOrURL ] = None , proxy_auth : Optional [ BasicAuth ] = None , ssl : Union [ SSLContext , bool , None , Fingerprint ] = None , verify_ssl : Optional [ bool ] = None , fingerprint : Optional [ bytes ] = None , ssl_context : Optional [ SSLContext ] = None , proxy_headers : Optional [ LooseHeaders ] = None , compress : int = 0 , max_msg_size : int = 4 * 1024 * 1024 , ) -> \"_WSRequestContextManager\" : \"\"\"Initiate websocket connection.\"\"\" return _WSRequestContextManager ( self . _ws_connect ( url , method = method , protocols = protocols , timeout = timeout , receive_timeout = receive_timeout , autoclose = autoclose , autoping = autoping , heartbeat = heartbeat , auth = auth , origin = origin , params = params , headers = headers , proxy = proxy , proxy_auth = proxy_auth , ssl = ssl , verify_ssl = verify_ssl , fingerprint = fingerprint , ssl_context = ssl_context , proxy_headers = proxy_headers , compress = compress , max_msg_size = max_msg_size , ) ) async def _ws_connect ( self , url : StrOrURL , * , method : str = hdrs . METH_GET , protocols : Iterable [ str ] = (), timeout : float = 10.0 , receive_timeout : Optional [ float ] = None , autoclose : bool = True , autoping : bool = True , heartbeat : Optional [ float ] = None , auth : Optional [ BasicAuth ] = None , origin : Optional [ str ] = None , params : Optional [ Mapping [ str , str ]] = None , headers : Optional [ LooseHeaders ] = None , proxy : Optional [ StrOrURL ] = None , proxy_auth : Optional [ BasicAuth ] = None , ssl : Union [ SSLContext , bool , None , Fingerprint ] = None , verify_ssl : Optional [ bool ] = None , fingerprint : Optional [ bytes ] = None , ssl_context : Optional [ SSLContext ] = None , proxy_headers : Optional [ LooseHeaders ] = None , compress : int = 0 , max_msg_size : int = 4 * 1024 * 1024 , ) -> ClientWebSocketResponse : if headers is None : real_headers : CIMultiDict [ str ] = CIMultiDict () else : real_headers = CIMultiDict ( headers ) default_headers = { hdrs . UPGRADE : \"websocket\" , hdrs . CONNECTION : \"upgrade\" , hdrs . SEC_WEBSOCKET_VERSION : \"13\" , } for key , value in default_headers . items (): real_headers . setdefault ( key , value ) sec_key = base64 . b64encode ( os . urandom ( 16 )) real_headers [ hdrs . SEC_WEBSOCKET_KEY ] = sec_key . decode () if protocols : real_headers [ hdrs . SEC_WEBSOCKET_PROTOCOL ] = \",\" . join ( protocols ) if origin is not None : real_headers [ hdrs . ORIGIN ] = origin if compress : extstr = ws_ext_gen ( compress = compress ) real_headers [ hdrs . SEC_WEBSOCKET_EXTENSIONS ] = extstr ssl = _merge_ssl_params ( ssl , verify_ssl , ssl_context , fingerprint ) # send request resp = await self . request ( method , url , params = params , headers = real_headers , read_until_eof = False , auth = auth , proxy = proxy , proxy_auth = proxy_auth , ssl = ssl , proxy_headers = proxy_headers , ) try : # check handshake if resp . status != 101 : raise WSServerHandshakeError ( resp . request_info , resp . history , message = \"Invalid response status\" , status = resp . status , headers = resp . headers , ) if resp . headers . get ( hdrs . UPGRADE , \"\" ) . lower () != \"websocket\" : raise WSServerHandshakeError ( resp . request_info , resp . history , message = \"Invalid upgrade header\" , status = resp . status , headers = resp . headers , ) if resp . headers . get ( hdrs . CONNECTION , \"\" ) . lower () != \"upgrade\" : raise WSServerHandshakeError ( resp . request_info , resp . history , message = \"Invalid connection header\" , status = resp . status , headers = resp . headers , ) # key calculation r_key = resp . headers . get ( hdrs . SEC_WEBSOCKET_ACCEPT , \"\" ) match = base64 . b64encode ( hashlib . sha1 ( sec_key + WS_KEY ) . digest ()) . decode () if r_key != match : raise WSServerHandshakeError ( resp . request_info , resp . history , message = \"Invalid challenge response\" , status = resp . status , headers = resp . headers , ) # websocket protocol protocol = None if protocols and hdrs . SEC_WEBSOCKET_PROTOCOL in resp . headers : resp_protocols = [ proto . strip () for proto in resp . headers [ hdrs . SEC_WEBSOCKET_PROTOCOL ] . split ( \",\" ) ] for proto in resp_protocols : if proto in protocols : protocol = proto break # websocket compress notakeover = False if compress : compress_hdrs = resp . headers . get ( hdrs . SEC_WEBSOCKET_EXTENSIONS ) if compress_hdrs : try : compress , notakeover = ws_ext_parse ( compress_hdrs ) except WSHandshakeError as exc : raise WSServerHandshakeError ( resp . request_info , resp . history , message = exc . args [ 0 ], status = resp . status , headers = resp . headers , ) from exc else : compress = 0 notakeover = False conn = resp . connection assert conn is not None conn_proto = conn . protocol assert conn_proto is not None transport = conn . transport assert transport is not None reader : FlowControlDataQueue [ WSMessage ] = FlowControlDataQueue ( conn_proto , 2 ** 16 , loop = self . _loop ) conn_proto . set_parser ( WebSocketReader ( reader , max_msg_size ), reader ) writer = WebSocketWriter ( conn_proto , transport , use_mask = True , compress = compress , notakeover = notakeover , ) except BaseException : resp . close () raise else : return self . _ws_response_class ( reader , writer , protocol , resp , timeout , autoclose , autoping , self . _loop , receive_timeout = receive_timeout , heartbeat = heartbeat , compress = compress , client_notakeover = notakeover , ) def _prepare_headers ( self , headers : Optional [ LooseHeaders ]) -> \"CIMultiDict[str]\" : \"\"\"Add default headers and transform it to CIMultiDict\"\"\" # Convert headers to MultiDict result = CIMultiDict ( self . _default_headers ) if headers : if not isinstance ( headers , ( MultiDictProxy , MultiDict )): headers = CIMultiDict ( headers ) added_names : Set [ str ] = set () for key , value in headers . items (): if key in added_names : result . add ( key , value ) else : result [ key ] = value added_names . add ( key ) return result def get ( self , url : StrOrURL , * , allow_redirects : bool = True , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP GET request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_GET , url , allow_redirects = allow_redirects , ** kwargs ) ) def options ( self , url : StrOrURL , * , allow_redirects : bool = True , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP OPTIONS request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_OPTIONS , url , allow_redirects = allow_redirects , ** kwargs ) ) def head ( self , url : StrOrURL , * , allow_redirects : bool = False , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP HEAD request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_HEAD , url , allow_redirects = allow_redirects , ** kwargs ) ) def post ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP POST request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_POST , url , data = data , ** kwargs ) ) def put ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP PUT request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_PUT , url , data = data , ** kwargs ) ) def patch ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP PATCH request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_PATCH , url , data = data , ** kwargs ) ) def delete ( self , url : StrOrURL , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP DELETE request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_DELETE , url , ** kwargs )) async def close ( self ) -> None : \"\"\"Close underlying connector. Release all acquired resources. \"\"\" if not self . closed : if self . _connector is not None and self . _connector_owner : await self . _connector . close () self . _connector = None @property def closed ( self ) -> bool : \"\"\"Is client session closed. A readonly property. \"\"\" return self . _connector is None or self . _connector . closed @property def connector ( self ) -> Optional [ BaseConnector ]: \"\"\"Connector instance used for the session.\"\"\" return self . _connector @property def cookie_jar ( self ) -> AbstractCookieJar : \"\"\"The session cookies.\"\"\" return self . _cookie_jar @property def version ( self ) -> Tuple [ int , int ]: \"\"\"The session HTTP protocol version.\"\"\" return self . _version @property def requote_redirect_url ( self ) -> bool : \"\"\"Do URL requoting on redirection handling.\"\"\" return self . _requote_redirect_url @requote_redirect_url . setter def requote_redirect_url ( self , val : bool ) -> None : \"\"\"Do URL requoting on redirection handling.\"\"\" warnings . warn ( \"session.requote_redirect_url modification \" \"is deprecated #2778\" , DeprecationWarning , stacklevel = 2 , ) self . _requote_redirect_url = val @property def loop ( self ) -> asyncio . AbstractEventLoop : \"\"\"Session's loop.\"\"\" warnings . warn ( \"client.loop property is deprecated\" , DeprecationWarning , stacklevel = 2 ) return self . _loop @property def timeout ( self ) -> ClientTimeout : \"\"\"Timeout for the session.\"\"\" return self . _timeout @property def headers ( self ) -> \"CIMultiDict[str]\" : \"\"\"The default headers of the client session.\"\"\" return self . _default_headers @property def skip_auto_headers ( self ) -> FrozenSet [ istr ]: \"\"\"Headers for which autogeneration should be skipped\"\"\" return self . _skip_auto_headers @property def auth ( self ) -> Optional [ BasicAuth ]: \"\"\"An object that represents HTTP Basic Authorization\"\"\" return self . _default_auth @property def json_serialize ( self ) -> JSONEncoder : \"\"\"Json serializer callable\"\"\" return self . _json_serialize @property def connector_owner ( self ) -> bool : \"\"\"Should connector be closed on session closing\"\"\" return self . _connector_owner @property def raise_for_status ( self , ) -> Union [ bool , Callable [[ ClientResponse ], Awaitable [ None ]]]: \"\"\"Should `ClientResponse.raise_for_status()` be called for each response.\"\"\" return self . _raise_for_status @property def auto_decompress ( self ) -> bool : \"\"\"Should the body response be automatically decompressed.\"\"\" return self . _auto_decompress @property def trust_env ( self ) -> bool : \"\"\" Should proxies information from environment or netrc be trusted. Information is from HTTP_PROXY / HTTPS_PROXY environment variables or ~/.netrc file if present. \"\"\" return self . _trust_env @property def trace_configs ( self ) -> List [ TraceConfig ]: \"\"\"A list of TraceConfig instances used for client tracing\"\"\" return self . _trace_configs def detach ( self ) -> None : \"\"\"Detach connector from session without closing the former. Session is switched to closed state anyway. \"\"\" self . _connector = None def __enter__ ( self ) -> None : raise TypeError ( \"Use async with instead\" ) def __exit__ ( self , exc_type : Optional [ Type [ BaseException ]], exc_val : Optional [ BaseException ], exc_tb : Optional [ TracebackType ], ) -> None : # __exit__ should exist in pair with __enter__ but never executed pass # pragma: no cover async def __aenter__ ( self ) -> \"ClientSession\" : return self async def __aexit__ ( self , exc_type : Optional [ Type [ BaseException ]], exc_val : Optional [ BaseException ], exc_tb : Optional [ TracebackType ], ) -> None : await self . close ()","title":"ClientSession class"},{"location":"api/#aiotest.client.ClientSession.closed","text":"Is client session closed. A readonly property.","title":"closed"},{"location":"api/#aiotest.client.ClientSession.connector","text":"Connector instance used for the session.","title":"connector"},{"location":"api/#aiotest.client.ClientSession.cookie_jar","text":"The session cookies.","title":"cookie_jar"},{"location":"api/#aiotest.client.ClientSession.headers","text":"The default headers of the client session.","title":"headers"},{"location":"api/#aiotest.client.ClientSession.timeout","text":"Timeout for the session.","title":"timeout"},{"location":"api/#aiotest.client.ClientSession.close","text":"Close underlying connector. Release all acquired resources. Source code in aiotest\\client.py async def close ( self ) -> None : \"\"\"Close underlying connector. Release all acquired resources. \"\"\" if not self . closed : if self . _connector is not None and self . _connector_owner : await self . _connector . close () self . _connector = None","title":"close()"},{"location":"api/#aiotest.client.ClientSession.delete","text":"Perform HTTP DELETE request. Source code in aiotest\\client.py def delete ( self , url : StrOrURL , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP DELETE request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_DELETE , url , ** kwargs ))","title":"delete()"},{"location":"api/#aiotest.client.ClientSession.detach","text":"Detach connector from session without closing the former. Session is switched to closed state anyway. Source code in aiotest\\client.py def detach ( self ) -> None : \"\"\"Detach connector from session without closing the former. Session is switched to closed state anyway. \"\"\" self . _connector = None","title":"detach()"},{"location":"api/#aiotest.client.ClientSession.get","text":"Perform HTTP GET request. Source code in aiotest\\client.py def get ( self , url : StrOrURL , * , allow_redirects : bool = True , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP GET request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_GET , url , allow_redirects = allow_redirects , ** kwargs ) )","title":"get()"},{"location":"api/#aiotest.client.ClientSession.head","text":"Perform HTTP HEAD request. Source code in aiotest\\client.py def head ( self , url : StrOrURL , * , allow_redirects : bool = False , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP HEAD request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_HEAD , url , allow_redirects = allow_redirects , ** kwargs ) )","title":"head()"},{"location":"api/#aiotest.client.ClientSession.options","text":"Perform HTTP OPTIONS request. Source code in aiotest\\client.py def options ( self , url : StrOrURL , * , allow_redirects : bool = True , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP OPTIONS request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_OPTIONS , url , allow_redirects = allow_redirects , ** kwargs ) )","title":"options()"},{"location":"api/#aiotest.client.ClientSession.patch","text":"Perform HTTP PATCH request. Source code in aiotest\\client.py def patch ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP PATCH request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_PATCH , url , data = data , ** kwargs ) )","title":"patch()"},{"location":"api/#aiotest.client.ClientSession.post","text":"Perform HTTP POST request. Source code in aiotest\\client.py def post ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP POST request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_POST , url , data = data , ** kwargs ) )","title":"post()"},{"location":"api/#aiotest.client.ClientSession.put","text":"Perform HTTP PUT request. Source code in aiotest\\client.py def put ( self , url : StrOrURL , * , data : Any = None , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP PUT request.\"\"\" return _RequestContextManager ( self . _request ( hdrs . METH_PUT , url , data = data , ** kwargs ) )","title":"put()"},{"location":"api/#aiotest.client.ClientSession.request","text":"Perform HTTP request. Source code in aiotest\\client.py def request ( self , method : str , url : StrOrURL , ** kwargs : Any ) -> \"_RequestContextManager\" : \"\"\"Perform HTTP request.\"\"\" return _RequestContextManager ( self . _request ( method , url , ** kwargs ))","title":"request()"},{"location":"api/#loadusershape-class","text":"A simple load test shape class used to control the shape of load generated during a load test. Source code in aiotest\\shape.py class LoadUserShape ( metaclass = ABCMeta ): \"\"\" A simple load test shape class used to control the shape of load generated during a load test. \"\"\" def __init__ ( self ): self . start_time = default_timer () def reset_time ( self ): \"Resets start time back to 0\" self . start_time = default_timer () def get_run_time ( self ): \"Calculates run time in seconds of the load user\" return default_timer () - self . start_time @abstractmethod def tick ( self ): \"\"\" Returns a tuple with 2 elements to control the running load user: user_count -- Total user count rate -- Number of users to start/stop per second when changing number of users if 'None' is returned then the running load user will be stopped. \"\"\" return None","title":"LoadUserShape class"},{"location":"api/#aiotest.shape.LoadUserShape.get_run_time","text":"Calculates run time in seconds of the load user Source code in aiotest\\shape.py def get_run_time ( self ): \"Calculates run time in seconds of the load user\" return default_timer () - self . start_time","title":"get_run_time()"},{"location":"api/#aiotest.shape.LoadUserShape.reset_time","text":"Resets start time back to 0 Source code in aiotest\\shape.py def reset_time ( self ): \"Resets start time back to 0\" self . start_time = default_timer ()","title":"reset_time()"},{"location":"api/#aiotest.shape.LoadUserShape.tick","text":"Returns a tuple with 2 elements to control the running load user: user_count -- Total user count rate -- Number of users to start/stop per second when changing number of users if 'None' is returned then the running load user will be stopped. Source code in aiotest\\shape.py @abstractmethod def tick ( self ): \"\"\" Returns a tuple with 2 elements to control the running load user: user_count -- Total user count rate -- Number of users to start/stop per second when changing number of users if 'None' is returned then the running load user will be stopped. \"\"\" return None","title":"tick()"},{"location":"api/#runner-class","text":"Source code in aiotest\\runners.py class Runner : def __init__ ( self , user_classes , shape_class , options ): self . user_classes = user_classes self . shape_class = shape_class self . options = options self . cpu_usage = 0 self . state = STATE_INIT self . user_instances = [] self . tasks = [] self . is_quit = False def __del__ ( self ): for task in self . tasks : if not task . done (): task . cancel () @property def user_count ( self ): \"Returns the number of running user tasks, a user equals a task\" return len ([ instances for instances in self . user_instances if not instances . task . done ()]) def update_state ( self , new_state ): logger . debug ( f \"Updating state to { new_state } , old state was { self . state } \" ) self . state = new_state def weight_users ( self , amount ): \"\"\" Distributes the amount of users for each User-class according to it's weight returns a list \"bucket\" with the weighted users \"\"\" weight_sum = 0 for user in self . user_classes : if self . options . host : user . host = self . options . host try : if isinstance ( user . weight , int ) and user . weight >= 1 : weight_sum += user . weight else : raise ValueError ( \"weigth value must be an int type and >= 1\" ) except KeyError : raise KeyError ( \"Userclass must have weight attribute\" ) residuals = {} bucket = [] for user in self . user_classes : # create users depending on weight percent = user . weight / weight_sum num_users = round ( amount * percent ) residuals [ user ] = amount * percent - num_users bucket . extend ([ user for i in range ( num_users )]) if len ( bucket ) < amount : for user in [ l for l , r in sorted ( residuals . items (), key = lambda x : x [ 1 ], reverse = True )][: amount - len ( bucket )]: bucket . append ( user ) elif len ( bucket ) > amount : for user in [ l for l , r in sorted ( residuals . items (), key = lambda x : x [ 1 ])][: len ( bucket ) - amount ]: bucket . remove ( user ) # [<class 'User01'>, <class 'User02'>,...] return bucket async def start ( self , user_count , rate ): \"Create user tasks for a load test master entry\" if not isinstance ( user_count , int ) or user_count <= 0 : logger . warning ( f \" { user_count } mast be int type and >= 1\" ) sys . exit ( 1 ) if rate <= 0 or rate > user_count : logger . warning ( f \" { rate } mast > 0 and < user_count { user_count } \" ) sys . exit ( 1 ) if rate % 1 != 0 : logger . warning ( f \" { rate } rate fractional part is't 0\" ) # Dynamically changing the user count if self . state in [ STATE_STARTING , STATE_RUNNING ]: logger . debug ( f \"Updating running test with { user_count } users, { rate : .2f } rate.\" ) self . update_state ( STATE_STARTING ) if self . user_count > user_count : # stop some users stop_count = self . user_count - user_count await self . stop_users ( stop_count , rate ) self . update_state ( STATE_RUNNING ) elif self . user_count < user_count : # start some users start_count = user_count - self . user_count await self . start_users ( start_count , rate ) self . update_state ( STATE_RUNNING ) else : self . update_state ( STATE_RUNNING ) elif self . state == STATE_INIT : await self . start_users ( user_count , rate ) self . update_state ( STATE_RUNNING ) await events . start_complete . fire ( user_count = self . user_count , runner = self ) else : logger . error ( f \"runner state is { self . state } \" ) sys . exit ( 1 ) async def start_users ( self , user_count , rate ): \"Create a specified number of user tasks, a user equals a task\" bucket = self . weight_users ( user_count ) # [<class 'User01'>, <class 'User02'>,...] if self . state == STATE_INIT : self . update_state ( STATE_STARTING ) existing_count = self . user_count logger . info ( f \"starting { len ( bucket ) } users at the rate { rate } users/s, ( { existing_count } users already running)...\" ) start_count = dict (( u . __name__ , 0 ) for u in self . user_classes ) # {'User01': 0, 'User02': 0...} sleep_time = 1 / rate for i in range ( len ( bucket )): user_class = bucket . pop () start_count [ user_class . __name__ ] += 1 new_user = user_class () new_user . start_user () self . user_instances . append ( new_user ) await asyncio . sleep ( sleep_time ) if self . user_count % 10 == 0 : logger . debug ( f \" { self . user_count } users started\" ) if not bucket : logger . info ( f \"All users started: { ', ' . join ([ f ' { name } : { count } ' for name , count in start_count . items ()]) } \" ) else : logger . error ( f \" { bucket } have user_class don't started\" ) sys . exit ( 1 ) async def stop_users ( self , user_count , rate ): \"Cancels a specified number of user tasks\" bucket = self . weight_users ( user_count ) # [<class 'User01'>, <class 'User02'>,...] user_count = len ( bucket ) stop_users = [] for instances in self . user_instances : if not instances . task . done (): for user_class in bucket : if isinstance ( instances , user_class ): stop_users . append ( instances ) bucket . remove ( user_class ) break if rate >= user_count : sleep_time = 0 logger . info ( f \"Stopping { user_count } users immediately\" ) else : sleep_time = 1 / rate logger . info ( f \"Stoping { user_count } users at rate of { rate } users/s\" ) for instances in stop_users : await instances . stop_user () await asyncio . sleep ( sleep_time ) self . user_instances = [ instances for instances in self . user_instances if not instances . task . done ()] stop_users = [ instances for instances in stop_users if not instances . task . done ()] if stop_users : logger . warning ( f \"There are still user tasks uncancelled: { len ( stop_users ) } \" ) async def stop ( self ): \"Cancel all user tasks\" logger . debug ( \"Stopping all users\" ) await self . stop_users ( self . user_count , self . user_count ) await asyncio . sleep ( 0.5 ) logger . debug ( f \"all user task is done: { all ([ instances . task . done () for instances in self . user_instances ]) } \" ) for task in self . tasks : if task . get_name () == \"users_tasks\" and not task . done (): task . cancel () self . tasks . remove ( task ) break self . update_state ( STATE_STOPPED ) async def quit ( self ): \"Exit the load test and cancel all runner tasks\" if not self . is_quit : self . is_quit = True await self . stop () await asyncio . sleep ( 0.5 ) await events . quitting . fire () for task in self . tasks : if not task . done () and task != asyncio . current_task (): task . cancel () await asyncio . sleep ( 0.1 ) self . tasks = [ task for task in self . tasks if not task . done ()] logger . debug ( f \"runner's tasks is done: { len ( self . tasks ) == 1 } \" ) def start_shape ( self ): \"Create a load test policy task\" shape_task = asyncio . create_task ( self . shape_run (), name = \"shape_task\" ) self . tasks . append ( shape_task ) async def shape_run ( self ): \"Execute the specified load test policy\" logger . info ( \"Shape starting\" ) shape_last = None while True : shape_new = self . shape_class . tick () if shape_new is None : logger . info ( \"Shape test stopping\" ) await self . quit () return elif shape_last == shape_new : await asyncio . sleep ( 1 ) else : logger . debug ( shape_new ) user_count , rate = shape_new logger . info ( f \"Shape test updating to { user_count } users at { rate } rate\" ) await self . start ( user_count = user_count , rate = rate ) shape_last = shape_new","title":"Runner class"},{"location":"api/#aiotest.runners.Runner.user_count","text":"Returns the number of running user tasks, a user equals a task","title":"user_count"},{"location":"api/#aiotest.runners.Runner.quit","text":"Exit the load test and cancel all runner tasks Source code in aiotest\\runners.py async def quit ( self ): \"Exit the load test and cancel all runner tasks\" if not self . is_quit : self . is_quit = True await self . stop () await asyncio . sleep ( 0.5 ) await events . quitting . fire () for task in self . tasks : if not task . done () and task != asyncio . current_task (): task . cancel () await asyncio . sleep ( 0.1 ) self . tasks = [ task for task in self . tasks if not task . done ()] logger . debug ( f \"runner's tasks is done: { len ( self . tasks ) == 1 } \" )","title":"quit()"},{"location":"api/#aiotest.runners.Runner.shape_run","text":"Execute the specified load test policy Source code in aiotest\\runners.py async def shape_run ( self ): \"Execute the specified load test policy\" logger . info ( \"Shape starting\" ) shape_last = None while True : shape_new = self . shape_class . tick () if shape_new is None : logger . info ( \"Shape test stopping\" ) await self . quit () return elif shape_last == shape_new : await asyncio . sleep ( 1 ) else : logger . debug ( shape_new ) user_count , rate = shape_new logger . info ( f \"Shape test updating to { user_count } users at { rate } rate\" ) await self . start ( user_count = user_count , rate = rate ) shape_last = shape_new","title":"shape_run()"},{"location":"api/#aiotest.runners.Runner.start","text":"Create user tasks for a load test master entry Source code in aiotest\\runners.py async def start ( self , user_count , rate ): \"Create user tasks for a load test master entry\" if not isinstance ( user_count , int ) or user_count <= 0 : logger . warning ( f \" { user_count } mast be int type and >= 1\" ) sys . exit ( 1 ) if rate <= 0 or rate > user_count : logger . warning ( f \" { rate } mast > 0 and < user_count { user_count } \" ) sys . exit ( 1 ) if rate % 1 != 0 : logger . warning ( f \" { rate } rate fractional part is't 0\" ) # Dynamically changing the user count if self . state in [ STATE_STARTING , STATE_RUNNING ]: logger . debug ( f \"Updating running test with { user_count } users, { rate : .2f } rate.\" ) self . update_state ( STATE_STARTING ) if self . user_count > user_count : # stop some users stop_count = self . user_count - user_count await self . stop_users ( stop_count , rate ) self . update_state ( STATE_RUNNING ) elif self . user_count < user_count : # start some users start_count = user_count - self . user_count await self . start_users ( start_count , rate ) self . update_state ( STATE_RUNNING ) else : self . update_state ( STATE_RUNNING ) elif self . state == STATE_INIT : await self . start_users ( user_count , rate ) self . update_state ( STATE_RUNNING ) await events . start_complete . fire ( user_count = self . user_count , runner = self ) else : logger . error ( f \"runner state is { self . state } \" ) sys . exit ( 1 )","title":"start()"},{"location":"api/#aiotest.runners.Runner.start_shape","text":"Create a load test policy task Source code in aiotest\\runners.py def start_shape ( self ): \"Create a load test policy task\" shape_task = asyncio . create_task ( self . shape_run (), name = \"shape_task\" ) self . tasks . append ( shape_task )","title":"start_shape()"},{"location":"api/#aiotest.runners.Runner.start_users","text":"Create a specified number of user tasks, a user equals a task Source code in aiotest\\runners.py async def start_users ( self , user_count , rate ): \"Create a specified number of user tasks, a user equals a task\" bucket = self . weight_users ( user_count ) # [<class 'User01'>, <class 'User02'>,...] if self . state == STATE_INIT : self . update_state ( STATE_STARTING ) existing_count = self . user_count logger . info ( f \"starting { len ( bucket ) } users at the rate { rate } users/s, ( { existing_count } users already running)...\" ) start_count = dict (( u . __name__ , 0 ) for u in self . user_classes ) # {'User01': 0, 'User02': 0...} sleep_time = 1 / rate for i in range ( len ( bucket )): user_class = bucket . pop () start_count [ user_class . __name__ ] += 1 new_user = user_class () new_user . start_user () self . user_instances . append ( new_user ) await asyncio . sleep ( sleep_time ) if self . user_count % 10 == 0 : logger . debug ( f \" { self . user_count } users started\" ) if not bucket : logger . info ( f \"All users started: { ', ' . join ([ f ' { name } : { count } ' for name , count in start_count . items ()]) } \" ) else : logger . error ( f \" { bucket } have user_class don't started\" ) sys . exit ( 1 )","title":"start_users()"},{"location":"api/#aiotest.runners.Runner.stop","text":"Cancel all user tasks Source code in aiotest\\runners.py async def stop ( self ): \"Cancel all user tasks\" logger . debug ( \"Stopping all users\" ) await self . stop_users ( self . user_count , self . user_count ) await asyncio . sleep ( 0.5 ) logger . debug ( f \"all user task is done: { all ([ instances . task . done () for instances in self . user_instances ]) } \" ) for task in self . tasks : if task . get_name () == \"users_tasks\" and not task . done (): task . cancel () self . tasks . remove ( task ) break self . update_state ( STATE_STOPPED )","title":"stop()"},{"location":"api/#aiotest.runners.Runner.stop_users","text":"Cancels a specified number of user tasks Source code in aiotest\\runners.py async def stop_users ( self , user_count , rate ): \"Cancels a specified number of user tasks\" bucket = self . weight_users ( user_count ) # [<class 'User01'>, <class 'User02'>,...] user_count = len ( bucket ) stop_users = [] for instances in self . user_instances : if not instances . task . done (): for user_class in bucket : if isinstance ( instances , user_class ): stop_users . append ( instances ) bucket . remove ( user_class ) break if rate >= user_count : sleep_time = 0 logger . info ( f \"Stopping { user_count } users immediately\" ) else : sleep_time = 1 / rate logger . info ( f \"Stoping { user_count } users at rate of { rate } users/s\" ) for instances in stop_users : await instances . stop_user () await asyncio . sleep ( sleep_time ) self . user_instances = [ instances for instances in self . user_instances if not instances . task . done ()] stop_users = [ instances for instances in stop_users if not instances . task . done ()] if stop_users : logger . warning ( f \"There are still user tasks uncancelled: { len ( stop_users ) } \" )","title":"stop_users()"},{"location":"api/#aiotest.runners.Runner.weight_users","text":"Distributes the amount of users for each User-class according to it's weight returns a list \"bucket\" with the weighted users Source code in aiotest\\runners.py def weight_users ( self , amount ): \"\"\" Distributes the amount of users for each User-class according to it's weight returns a list \"bucket\" with the weighted users \"\"\" weight_sum = 0 for user in self . user_classes : if self . options . host : user . host = self . options . host try : if isinstance ( user . weight , int ) and user . weight >= 1 : weight_sum += user . weight else : raise ValueError ( \"weigth value must be an int type and >= 1\" ) except KeyError : raise KeyError ( \"Userclass must have weight attribute\" ) residuals = {} bucket = [] for user in self . user_classes : # create users depending on weight percent = user . weight / weight_sum num_users = round ( amount * percent ) residuals [ user ] = amount * percent - num_users bucket . extend ([ user for i in range ( num_users )]) if len ( bucket ) < amount : for user in [ l for l , r in sorted ( residuals . items (), key = lambda x : x [ 1 ], reverse = True )][: amount - len ( bucket )]: bucket . append ( user ) elif len ( bucket ) > amount : for user in [ l for l , r in sorted ( residuals . items (), key = lambda x : x [ 1 ])][: len ( bucket ) - amount ]: bucket . remove ( user ) # [<class 'User01'>, <class 'User02'>,...] return bucket","title":"weight_users()"},{"location":"api/#localrunner-class","text":"Source code in aiotest\\runners.py class LocalRunner ( Runner ): def __init__ ( self , user_classes , shape_class , options ): super () . __init__ ( user_classes , shape_class , options ) user_count_task = asyncio . create_task ( exporter_user_count ( self ), name = \"user_count_task\" ) prometheus_task = asyncio . create_task ( prometheus_server ( self . options . prometheus_port ), name = \"prometheus\" ) monitor_cpu_task = asyncio . create_task ( exporter_cpu_usage ( self ), name = \"monitor_cpu\" ) self . tasks . append ( user_count_task ) self . tasks . append ( prometheus_task ) self . tasks . append ( monitor_cpu_task ) async def start ( self , user_count , rate ): if rate > 100 : logger . warning ( \"Your selected rate is very high (>100), and this is known to sometimes cause issues. Do you really need to ramp up that fast?\" ) if self . state == STATE_INIT : await events . test_start . fire ( runner = self ) for task in asyncio . all_tasks (): if task . get_name () == \"users_tasks\" and not task . done (): # cancel existing task(name='users_tasks') before we start a new one task . cancel () break users_tasks = asyncio . create_task ( super () . start ( user_count , rate ), name = \"users_tasks\" ) self . tasks . append ( users_tasks ) async def stop ( self ): # if self.state == STATE_STOPPED: # return await super () . stop () await events . test_stop . fire ( runner = self )","title":"LocalRunner class"},{"location":"api/#aiotest.runners.LocalRunner.start","text":"Create user tasks for a load test master entry Source code in aiotest\\runners.py async def start ( self , user_count , rate ): if rate > 100 : logger . warning ( \"Your selected rate is very high (>100), and this is known to sometimes cause issues. Do you really need to ramp up that fast?\" ) if self . state == STATE_INIT : await events . test_start . fire ( runner = self ) for task in asyncio . all_tasks (): if task . get_name () == \"users_tasks\" and not task . done (): # cancel existing task(name='users_tasks') before we start a new one task . cancel () break users_tasks = asyncio . create_task ( super () . start ( user_count , rate ), name = \"users_tasks\" ) self . tasks . append ( users_tasks )","title":"start()"},{"location":"api/#aiotest.runners.LocalRunner.stop","text":"Cancel all user tasks Source code in aiotest\\runners.py async def stop ( self ): # if self.state == STATE_STOPPED: # return await super () . stop () await events . test_stop . fire ( runner = self )","title":"stop()"},{"location":"api/#masterrunner-class","text":"Runner used to run distributed load tests across multiple processes and/or machines. Source code in aiotest\\runners.py class MasterRunner ( DistributedRunner ): \"\"\" Runner used to run distributed load tests across multiple processes and/or machines. \"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) class WorkerNodesDict ( dict ): def get_by_state ( self , state ): return [ c for c in self . values () if c . state == state ] @property def all ( self ): return self . values () @property def ready ( self ): return self . get_by_state ( STATE_INIT ) @property def starting ( self ): return self . get_by_state ( STATE_STARTING ) @property def running ( self ): return self . get_by_state ( STATE_RUNNING ) @property def missing ( self ): return self . get_by_state ( STATE_MISSING ) self . workers = WorkerNodesDict () self . server = Server ( self . master_bind_host , self . master_bind_port ) worekr_heartbeat_task = asyncio . create_task ( self . worker_heartbeat (), name = \"worekr_heartbeat\" ) worekr_listener_task = asyncio . create_task ( self . worekr_listener (), name = \"worekr_listener\" ) prometheus_task = asyncio . create_task ( prometheus_server ( self . options . prometheus_port ), name = \"prometheus\" ) monitor_cpu_task = asyncio . create_task ( exporter_cpu_usage ( self ), name = \"monitor_cpu\" ) self . tasks . append ( worekr_heartbeat_task ) self . tasks . append ( worekr_listener_task ) self . tasks . append ( prometheus_task ) self . tasks . append ( monitor_cpu_task ) @property def user_count ( self ): return sum ([ c . user_count for c in self . workers . values ()]) @property def worker_count ( self ): return len ( self . workers . ready ) + len ( self . workers . starting ) + len ( self . workers . running ) async def start ( self , user_count , rate ): num_workers = self . worker_count if not num_workers : logger . warning ( \"You are running in distributed mode but have no worker servers connected. Please connect workers prior to swarming.\" ) return worker_host = self . options . host worker_user_count = user_count // ( num_workers or 1 ) # \u6bcf\u4e2aworker\u5206\u914duser_count worker_rate = rate / ( num_workers or 1 ) # \u6bcf\u4e2aworker\u751f\u6210user\u901f\u7387 remainig = user_count % num_workers # \u5269\u4e0b\u7684user_count logger . info ( f \"Sending jobs of { worker_user_count } users and { worker_rate : .2f } rate to { num_workers } ready workers\" ) if worker_rate > 100 : logger . warning ( \"Your selected rate is very high (>100/worker), and this is known to sometimes cause issues. Do you really need to ramp up that fast?\" ) if self . state == STATE_INIT : await events . test_start . fire ( runner = self ) self . update_state ( STATE_STARTING ) for worker in ( self . workers . ready + self . workers . starting + self . workers . running ): data = { \"user_count\" : worker_user_count , \"rate\" : worker_rate , \"host\" : worker_host } if remainig > 0 : data [ \"user_count\" ] += 1 remainig -= 1 logger . debug ( f \"Sending start users message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"start\" , data , worker . id )) async def stop ( self ): logger . debug ( \"Stopping...\" ) # \u907f\u514d\u76f4\u5230tick\uff08\uff09\u53d1\u51fa\u53e6\u4e00\u4e2a\u53d8\u5316\u4fe1\u53f7\u65f6\u624d\u505c\u6b62 if self . shape_class : self . tactics_current = None for worker in self . workers . all : logger . debug ( f \"Sending stop message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"stop\" , None , worker . id )) await events . test_stop . fire ( runner = self ) self . update_state ( STATE_STOPPED ) async def quit ( self ): logger . debug ( \"Quitting...\" ) if not self . is_quit : self . is_quit = True await self . stop () await asyncio . sleep ( 0.5 ) for worker in self . workers . all : logger . debug ( f \"Sending quit message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"quit\" , None , worker . id )) await asyncio . sleep ( 0.5 ) # wait for final stats report from all workers await events . quitting . fire () for task in self . tasks : if not task . done (): task . cancel () self . server . close () async def worker_heartbeat ( self ): while True : await asyncio . sleep ( HEARTBEAT_INTERVAL ) if self . connection_broken : await self . reset_connection () continue for worker in self . workers . all : if worker . heartbeat < 0 and worker . state != STATE_MISSING : logger . warning ( f \"Worker { worker . id } failed to send heartbeat, setting state to missing.\" ) worker . state = STATE_MISSING worker . user_count = 0 if self . worker_count - len ( self . workers . missing ) <= 0 : logger . warning ( \"The last worker went missing, stopping test.\" ) await self . stop () else : worker . heartbeat -= 1 async def reset_connection ( self ): logger . info ( \"Reset connection to worker\" ) try : self . server . close () self . server = Server ( self . master_bind_host , self . master_bind_port ) except RPCError as e : logger . error ( f \"Temporary failure when resetting connection: { e } , will retry later.\" ) async def worekr_listener ( self ): while True : try : worker_id , msg = await self . server . recv_from_worker () msg . node_id = worker_id except RPCError as e : logger . error ( f \"RPCError found when receiving from worker: { e } \" ) self . connection_broken = True await asyncio . sleep ( FALLBACK_INTERVAL ) continue self . connection_broken = False if msg . type == \"heartbeat\" : if worker_id in self . workers : c = self . workers [ worker_id ] c . heartbeat = HEARTBEAT_LIVENESS c . state = msg . data [ \"state\" ] c . cpu_usage = msg . data [ \"cpu_usage\" ] if c . cpu_usage >= 90 : logger . warning ( f \"Worker { worker_id } exceeded CPU threshold\" ) elif msg . type == \"stats\" : if worker_id not in self . workers : logger . warning ( f \"Discarded report from unrecognized worker { worker_id } \" ) else : self . workers [ worker_id ] . user_count = msg . data [ \"user_count\" ] await events . worker_report . fire ( runner = self , worker_id = worker_id , data = msg . data ) elif msg . type == \"error\" : await events . user_error . fire ( runner = self , error = msg . data [ \"error\" ]) elif msg . type == \"ready\" : self . workers [ worker_id ] = WorkerNode ( id = worker_id ) logger . info ( f \"Worker { worker_id } reported as ready. Currently { self . worker_count } workers ready to swarm.\" ) if self . state in [ STATE_STARTING , STATE_RUNNING ]: # balance the load distribution when new worker joins self . start ( self . options . user_count , self . options . rate ) elif msg . type == \"starting\" : self . workers [ worker_id ] . state = STATE_STARTING elif msg . type == \"start_complete\" : self . workers [ worker_id ] . state = STATE_RUNNING self . workers [ worker_id ] . user_count = msg . data [ \"user_count\" ] if len ( self . workers . running ) == len ( self . workers . all ): self . update_state ( STATE_RUNNING ) await events . start_complete . fire ( user_count = self . user_count , runner = self ) elif msg . type == \"stopped\" : if worker_id in self . workers : del self . workers [ worker_id ] logger . info ( f \"Removing { worker_id } worker from running workers\" ) elif msg . type == \"quitted\" : if worker_id in self . workers : del self . workers [ worker_id ] logger . info ( f \"Worker { worker_id } quitted. Currently { self . worker_count } workers connected.\" )","title":"MasterRunner class"},{"location":"api/#aiotest.runners.MasterRunner.user_count","text":"Returns the number of running user tasks, a user equals a task","title":"user_count"},{"location":"api/#aiotest.runners.MasterRunner.quit","text":"Exit the load test and cancel all runner tasks Source code in aiotest\\runners.py async def quit ( self ): logger . debug ( \"Quitting...\" ) if not self . is_quit : self . is_quit = True await self . stop () await asyncio . sleep ( 0.5 ) for worker in self . workers . all : logger . debug ( f \"Sending quit message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"quit\" , None , worker . id )) await asyncio . sleep ( 0.5 ) # wait for final stats report from all workers await events . quitting . fire () for task in self . tasks : if not task . done (): task . cancel () self . server . close ()","title":"quit()"},{"location":"api/#aiotest.runners.MasterRunner.start","text":"Create user tasks for a load test master entry Source code in aiotest\\runners.py async def start ( self , user_count , rate ): num_workers = self . worker_count if not num_workers : logger . warning ( \"You are running in distributed mode but have no worker servers connected. Please connect workers prior to swarming.\" ) return worker_host = self . options . host worker_user_count = user_count // ( num_workers or 1 ) # \u6bcf\u4e2aworker\u5206\u914duser_count worker_rate = rate / ( num_workers or 1 ) # \u6bcf\u4e2aworker\u751f\u6210user\u901f\u7387 remainig = user_count % num_workers # \u5269\u4e0b\u7684user_count logger . info ( f \"Sending jobs of { worker_user_count } users and { worker_rate : .2f } rate to { num_workers } ready workers\" ) if worker_rate > 100 : logger . warning ( \"Your selected rate is very high (>100/worker), and this is known to sometimes cause issues. Do you really need to ramp up that fast?\" ) if self . state == STATE_INIT : await events . test_start . fire ( runner = self ) self . update_state ( STATE_STARTING ) for worker in ( self . workers . ready + self . workers . starting + self . workers . running ): data = { \"user_count\" : worker_user_count , \"rate\" : worker_rate , \"host\" : worker_host } if remainig > 0 : data [ \"user_count\" ] += 1 remainig -= 1 logger . debug ( f \"Sending start users message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"start\" , data , worker . id ))","title":"start()"},{"location":"api/#aiotest.runners.MasterRunner.stop","text":"Cancel all user tasks Source code in aiotest\\runners.py async def stop ( self ): logger . debug ( \"Stopping...\" ) # \u907f\u514d\u76f4\u5230tick\uff08\uff09\u53d1\u51fa\u53e6\u4e00\u4e2a\u53d8\u5316\u4fe1\u53f7\u65f6\u624d\u505c\u6b62 if self . shape_class : self . tactics_current = None for worker in self . workers . all : logger . debug ( f \"Sending stop message to worker { worker . id } \" ) await self . server . send_to_worker ( Message ( \"stop\" , None , worker . id )) await events . test_stop . fire ( runner = self ) self . update_state ( STATE_STOPPED )","title":"stop()"},{"location":"api/#workerrunner-class","text":"Runner used to run distributed load tests across multiple processes and/or machines. Source code in aiotest\\runners.py class WorkerRunner ( DistributedRunner ): \"Runner used to run distributed load tests across multiple processes and/or machines.\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . worker_state = STATE_INIT # \u4e3b\u673aip\u5730\u5740 + \u968f\u673a\u7801 self . worker_id = socket . gethostbyname ( socket . gethostname ()) + \"_\" + uuid4 () . hex self . worker = Client ( self . master_host , self . master_port , self . worker_id ) heartbeat_task = asyncio . create_task ( self . heartbeat (), name = \"heartbeat\" ) worker_run_task = asyncio . create_task ( self . worker_run (), name = \"worker_run\" ) monitor_cpu_task = asyncio . create_task ( exporter_cpu_usage ( self ), name = \"monitor_cpu\" ) self . tasks . append ( heartbeat_task ) self . tasks . append ( worker_run_task ) self . tasks . append ( monitor_cpu_task ) events . start_complete += self . on_start_complete events . quitting += self . on_quitting async def on_start_complete ( self , user_count , runner ): await self . worker . send ( Message ( \"start_complete\" , { \"user_count\" : user_count }, self . worker_id )) self . worker_state = STATE_RUNNING async def on_quitting ( self ): await self . worker . send ( Message ( \"quitted\" , None , self . worker_id )) async def heartbeat ( self ): while True : try : await self . worker . send ( Message ( \"heartbeat\" , { \"state\" : self . worker_state , \"cpu_usage\" : self . cpu_usage }, self . worker_id ) ) except RPCError as e : logger . error ( f \"RPCError found when sending heartbeat: { e } \" ) self . reset_connection () finally : await asyncio . sleep ( HEARTBEAT_INTERVAL ) async def reset_connection ( self ): logger . info ( \"Reset connection to master\" ) try : self . worker . close () self . worker = Client ( self . master_host , self . master_port , self . worker_id ) except RPCError as e : logger . error ( f \"Temporary failure when resetting connection: { e } , will retry later.\" ) async def worker_run ( self ): await self . worker . send ( Message ( \"ready\" , None , self . worker_id )) while True : try : msg = await self . worker . recv () except RPCError as e : logger . error ( f \"RPCError found when receiving from master: { e } \" ) continue if msg . type == \"start\" : self . worker_state = STATE_STARTING await self . worker . send ( Message ( \"starting\" , None , self . worker_id )) job = msg . data self . options . host = job [ \"host\" ] for task in asyncio . all_tasks (): if task . get_name () == \"users_tasks\" and not task . done (): # cancel existing task(name='start_user') before we start a new one task . cancel () break users_tasks = asyncio . create_task ( self . start ( job [ \"user_count\" ], job [ \"rate\" ]), name = \"users_tasks\" ) self . tasks . append ( users_tasks ) elif msg . type == \"stop\" : await self . stop () await self . worker . send ( Message ( \"stopped\" , None , self . worker_id )) self . worker_state = STATE_STOPPED await self . worker . send ( Message ( \"ready\" , None , self . worker_id )) self . worker_state = STATE_INIT elif msg . type == \"quit\" : logger . info ( \"Got quit message from master, shutting down...\" ) await self . quit () break async def quit ( self ): \"Exit the load test and cancel all runner tasks\" await super () . quit () if self . worker : self . worker . close ()","title":"WorkerRunner class"},{"location":"api/#aiotest.runners.WorkerRunner.quit","text":"Exit the load test and cancel all runner tasks Source code in aiotest\\runners.py async def quit ( self ): \"Exit the load test and cancel all runner tasks\" await super () . quit () if self . worker : self . worker . close ()","title":"quit()"},{"location":"api/#setup_logging","text":"Source code in aiotest\\log.py def setup_logging ( loglevel , logfile = None ): loglevel = loglevel . upper () logger . remove () logger . add ( sys . stderr , level = loglevel ) if logfile : logger . add ( logfile , level = loglevel , retention = \"1 days\" )","title":"setup_logging"},{"location":"api/#events-class","text":"Source code in aiotest\\events.py class EventHook : def __init__ ( self ): self . _handlers = [] def __iadd__ ( self , handler ): self . _handlers . append ( handler ) return self def __isub__ ( self , handler ): self . _handlers . remove ( handler ) return self async def fire ( self , ** kwargs ): for handler in self . _handlers : try : await handler ( ** kwargs ) except Exception as e : logger . error ( f \" { sys . exc_info ()[ 0 ] . __name__ } : { e } \" + \"\" . join ( traceback . format_tb ( sys . exc_info ()[ 2 ])) . strip ())","title":"Events class"},{"location":"command-line-options/","text":"Command Line Options Aiotest is configured mainly through command line arguments. aiotest --help usage: aiotest [options] [-h] [-f AIOTESTFILE] [-H HOST] [--master] [--worker] [--expect-workers EXPECT_WORKERS] [--master-host MASTER_HOST] [--master-port MASTER_PORT] [--master-bind-host MASTER_BIND_HOST] [--master-bind-port MASTER_BIND_PORT] [-u NUM_USERS] [-r RATE] [-t RUN_TIME] [--prometheus-port PROMETHEUS_PORT] [-b [BUCKETS ...]] [--loglevel LOGLEVEL] [--logfile LOGFILE] [--show-users-wight] [-V] asyncio is an easy to use, scriptable and scalable performance testing tool options: -h, --help show this help message and exit -f AIOTESTFILE, --aiotestfile AIOTESTFILE Python module file to import, e.g. '../other.py'. Default: aiotestfile -H HOST, --host HOST Host to load test in the following format: http://10.21.32.33 --master Set aiotest to run in distributed mode with this process as master --worker Set aiotest to run in distributed mode with this process as worker --expect-workers EXPECT_WORKERS How many workers master should expect to connect before starting the test --master-host MASTER_HOST Host or IP address of aiotest master for distributed load testing. Only used when running with --worker. Defaults to 127.0.0.1. --master-port MASTER_PORT The port to connect to that is used by the aiotest master for distributed load testing. Only used when running with --worker. Defaults to 5557. Note that workers will also connect to the master node on this port + 1. --master-bind-host MASTER_BIND_HOST Interfaces (hostname, ip) that aiotest master should bind to. Only used when running with --master. Defaults to * (all available interfaces). --master-bind-port MASTER_BIND_PORT Port that worker master should bind to. Only used when running with --master. Defaults to 5557. Note that aiotest will also use this port + 1, so by default the master node will bind to 5557 and 5558. -u NUM_USERS, --users NUM_USERS Number of concurrent users -r RATE, --rate RATE The rate per second in which users are started/stoped -t RUN_TIME, --run-time RUN_TIME Stop after the specified amount of time, e.g. (300s, 20m, 3h, 1h30m, etc.). Only used together with --no-web --prometheus-port PROMETHEUS_PORT Port that metrics are exposed over HTTP, to be read by the Prometheus server. -b [BUCKETS ...], --buckets [BUCKETS ...] Prometheus histogram buckets --loglevel LOGLEVEL, -L LOGLEVEL Choose between DEBUG/INFO/WARNING/ERROR/CRITICAL. Default is INFO. --logfile LOGFILE Path to log file. If not set, log will go to stdout/stderr --show-users-wight print json data of the users classes' execution wight -V, --version show program's version number and exit","title":"Command Line Options"},{"location":"command-line-options/#command-line-options","text":"Aiotest is configured mainly through command line arguments. aiotest --help usage: aiotest [options] [-h] [-f AIOTESTFILE] [-H HOST] [--master] [--worker] [--expect-workers EXPECT_WORKERS] [--master-host MASTER_HOST] [--master-port MASTER_PORT] [--master-bind-host MASTER_BIND_HOST] [--master-bind-port MASTER_BIND_PORT] [-u NUM_USERS] [-r RATE] [-t RUN_TIME] [--prometheus-port PROMETHEUS_PORT] [-b [BUCKETS ...]] [--loglevel LOGLEVEL] [--logfile LOGFILE] [--show-users-wight] [-V] asyncio is an easy to use, scriptable and scalable performance testing tool options: -h, --help show this help message and exit -f AIOTESTFILE, --aiotestfile AIOTESTFILE Python module file to import, e.g. '../other.py'. Default: aiotestfile -H HOST, --host HOST Host to load test in the following format: http://10.21.32.33 --master Set aiotest to run in distributed mode with this process as master --worker Set aiotest to run in distributed mode with this process as worker --expect-workers EXPECT_WORKERS How many workers master should expect to connect before starting the test --master-host MASTER_HOST Host or IP address of aiotest master for distributed load testing. Only used when running with --worker. Defaults to 127.0.0.1. --master-port MASTER_PORT The port to connect to that is used by the aiotest master for distributed load testing. Only used when running with --worker. Defaults to 5557. Note that workers will also connect to the master node on this port + 1. --master-bind-host MASTER_BIND_HOST Interfaces (hostname, ip) that aiotest master should bind to. Only used when running with --master. Defaults to * (all available interfaces). --master-bind-port MASTER_BIND_PORT Port that worker master should bind to. Only used when running with --master. Defaults to 5557. Note that aiotest will also use this port + 1, so by default the master node will bind to 5557 and 5558. -u NUM_USERS, --users NUM_USERS Number of concurrent users -r RATE, --rate RATE The rate per second in which users are started/stoped -t RUN_TIME, --run-time RUN_TIME Stop after the specified amount of time, e.g. (300s, 20m, 3h, 1h30m, etc.). Only used together with --no-web --prometheus-port PROMETHEUS_PORT Port that metrics are exposed over HTTP, to be read by the Prometheus server. -b [BUCKETS ...], --buckets [BUCKETS ...] Prometheus histogram buckets --loglevel LOGLEVEL, -L LOGLEVEL Choose between DEBUG/INFO/WARNING/ERROR/CRITICAL. Default is INFO. --logfile LOGFILE Path to log file. If not set, log will go to stdout/stderr --show-users-wight print json data of the users classes' execution wight -V, --version show program's version number and exit","title":"Command Line Options"},{"location":"custom-load-shape/","text":"Custom load shapes Sometimes a completely custom shaped load test is required that cannot be achieved by simply setting or changing the user count and spawn rate. For example, you might want to generate a load spike or ramp up and down at custom times. By using a LoadUserShape class you have full control over the user count and spawn rate at all times. Define a class inheriting the LoadUserShape class in your aiotest file. If this type of class is found then it will be automatically used by Aiotest. In this class you define a tick() method that returns a tuple with the desired user count and spawn rate (or None to stop the test). Aiotest will call the tick() method approximately once per second. In the class you also have access to the get_run_time() method, for checking how long the test has run for. Example from aiotest import AsyncHttpUser, LoadUserShape, logger class TestUserShoppingTrolley(AsyncHttpUser): \"\"\" Get the shopping cart and submit the order \"\"\" weight = 1 wait_time = 1 host = \"https://taobao.com\" token = None orderid = None async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] async def test_get_shopping_trolley(self): url = \"/GetShoppingTrolley\" hearders = {\"Authorization\": self.token} async with self.session.get(url=url, hearders=hearders) as resp: data = await resp.json() async def order_commit_test(self): url = \"/orderCommit\" hearders = {\"Authorization\": self.token} data = {\"orderAmount\": 100, \"coupon\": 30} async with self.session.post(url=url, json=data, hearders=hearders) as resp: data = await resp.json() self.orderid = data[\"order\"][\"Orderid\"] class TestShape(LoadUserShape): stages = [ {\"duration\": 180, \"user_count\": 30, \"rate\": 30}, {\"duration\": 360, \"user_count\": 60, \"rate\": 30}, {\"duration\": 540, \"user_count\": 120, \"rate\": 30}, {\"duration\": 720, \"user_count\": 60, \"rate\": 30}, {\"duration\": 900, \"user_count\": 30, \"rate\": 30}, ] def tick(self): run_time = self.get_run_time() for stage in self.stages: if run_time < stage[\"duration\"]: tick_data = (stage[\"user_count\"], stage[\"rate\"]) return tick_data return None Note The subclass of LoadUserShape must startswith or endswith Test . aiotestfile contains the LoadUserShape subclass, which ignores arguments specified on the command line : -u , -r , -t .","title":"Custom load shapes"},{"location":"custom-load-shape/#custom-load-shapes","text":"Sometimes a completely custom shaped load test is required that cannot be achieved by simply setting or changing the user count and spawn rate. For example, you might want to generate a load spike or ramp up and down at custom times. By using a LoadUserShape class you have full control over the user count and spawn rate at all times. Define a class inheriting the LoadUserShape class in your aiotest file. If this type of class is found then it will be automatically used by Aiotest. In this class you define a tick() method that returns a tuple with the desired user count and spawn rate (or None to stop the test). Aiotest will call the tick() method approximately once per second. In the class you also have access to the get_run_time() method, for checking how long the test has run for. Example from aiotest import AsyncHttpUser, LoadUserShape, logger class TestUserShoppingTrolley(AsyncHttpUser): \"\"\" Get the shopping cart and submit the order \"\"\" weight = 1 wait_time = 1 host = \"https://taobao.com\" token = None orderid = None async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] async def test_get_shopping_trolley(self): url = \"/GetShoppingTrolley\" hearders = {\"Authorization\": self.token} async with self.session.get(url=url, hearders=hearders) as resp: data = await resp.json() async def order_commit_test(self): url = \"/orderCommit\" hearders = {\"Authorization\": self.token} data = {\"orderAmount\": 100, \"coupon\": 30} async with self.session.post(url=url, json=data, hearders=hearders) as resp: data = await resp.json() self.orderid = data[\"order\"][\"Orderid\"] class TestShape(LoadUserShape): stages = [ {\"duration\": 180, \"user_count\": 30, \"rate\": 30}, {\"duration\": 360, \"user_count\": 60, \"rate\": 30}, {\"duration\": 540, \"user_count\": 120, \"rate\": 30}, {\"duration\": 720, \"user_count\": 60, \"rate\": 30}, {\"duration\": 900, \"user_count\": 30, \"rate\": 30}, ] def tick(self): run_time = self.get_run_time() for stage in self.stages: if run_time < stage[\"duration\"]: tick_data = (stage[\"user_count\"], stage[\"rate\"]) return tick_data return None Note The subclass of LoadUserShape must startswith or endswith Test . aiotestfile contains the LoadUserShape subclass, which ignores arguments specified on the command line : -u , -r , -t .","title":"Custom load shapes"},{"location":"events-hooks/","text":"Event hooks Aiotest comes with a number of event hooks that can be used to extend Aiotest in different ways. For example, here\u2019s how to set up an event listener that will trigger after a request is completed: from aiotest import AsyncHttpUser, events async def on_stats_request(runner, request_name, request_method, response_time, response_length, error): stats = { \"request_name\": request_name, \"request_method\": request_method, \"response_time\": response_time, \"response_length\": response_length, \"error\": error, \"user_count\": runner.user_count, } print(stats) events.stats_request += on_stats_request events.init_command_line_parser Event that can be used to add command line options to Aiotest events.init Called when initializing runner events.test_start Fired on each node when a new load test is started. It's not fired again if the number of users change during a test. events.stats_request Fired when a request in completed, successful or unsuccessful. This event is typically used to report requests when writing custom clients for aiotest. events.user_error Fired when an exception occurs inside the execution of a User class. events.worker_report Used when Aiotest is running in --master mode and is fired when the master server receives a report from a Aiotest worker server. This event can be used to aggregate data from the Aiotest worker servers. events.test_stop Fired on each node when a load test is stopped. events.quitting Fired after quitting events, just before process is exited. see more Events","title":"Event hooks"},{"location":"events-hooks/#event-hooks","text":"Aiotest comes with a number of event hooks that can be used to extend Aiotest in different ways. For example, here\u2019s how to set up an event listener that will trigger after a request is completed: from aiotest import AsyncHttpUser, events async def on_stats_request(runner, request_name, request_method, response_time, response_length, error): stats = { \"request_name\": request_name, \"request_method\": request_method, \"response_time\": response_time, \"response_length\": response_length, \"error\": error, \"user_count\": runner.user_count, } print(stats) events.stats_request += on_stats_request events.init_command_line_parser Event that can be used to add command line options to Aiotest events.init Called when initializing runner events.test_start Fired on each node when a new load test is started. It's not fired again if the number of users change during a test. events.stats_request Fired when a request in completed, successful or unsuccessful. This event is typically used to report requests when writing custom clients for aiotest. events.user_error Fired when an exception occurs inside the execution of a User class. events.worker_report Used when Aiotest is running in --master mode and is fired when the master server receives a report from a Aiotest worker server. This event can be used to aggregate data from the Aiotest worker servers. events.test_stop Fired on each node when a load test is stopped. events.quitting Fired after quitting events, just before process is exited. see more Events","title":"Event hooks"},{"location":"installation/","text":"Installation Install Python (3.11 or later) Install the package pip install aiotest Validate your installation aiotest -V Run aiotest aiotest -f aiotestfile.py","title":"Installation"},{"location":"installation/#installation","text":"Install Python (3.11 or later) Install the package pip install aiotest Validate your installation aiotest -V Run aiotest aiotest -f aiotestfile.py","title":"Installation"},{"location":"prometheus-grafana/","text":"Prometheus And Grafana Data Presentation Use prometheus to collect aiotest test data. The default stats_exporter port is 8089 , which can be reset on the command line aiotest -f aiotestfile -p 8000 Docker deploys jenkins,prometheus,grafana,redis,aiotest,node-exporter services Five hosts, root account, all files are in the same directory # linux host:port 192.168.0.10:22, CPU:4 docker-compose -f docker-compose.yml up -d docker-compose.yml version: '3' services: jenkins: image: jenkins/jenkins container_name: jenkins user: root restart: unless-stopped ports: - 8080:8080 - 50000:50000 volumes: - $PWD/jenkins_data:/var/jenkins_home - /var/run/docker.sock:/var/run/docker.sock - /root/.ssh:/root/.ssh prometheus: image: prom/prometheus:latest container_name: prometheus user: root restart: unless-stopped ports: - 9090:9090 command: - --config.file=/etc/prometheus/prometheus.yml volumes: - $PWD/prometheus.yml:/etc/prometheus/prometheus.yml:ro grafana: image: grafana/grafana-enterprise container_name: grafana user: root restart: unless-stopped ports: - 3000:3000 command: - --config.file=/etc/prometheus/prometheus.yml volumes: - $PWD/grafana_data:/var/lib/grafana depends_on: - prometheus redis: image: redis/redis-stack:latest container_name: redis user: root restart: unless-stopped volumes: - $PWD/redis_data/:/data - $PWD/local-redis-stack.conf:/redis-stack.conf ports: - 6379:6379 node-exporter: image: prom/node-exporter:latest container_name: node-exporter user: root restart: unless-stopped volumes: - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro command: - '--path.procfs=/host/proc' - '--path.rootfs=/rootfs' - '--path.sysfs=/host/sys' - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)' ports: - 9100:9100 aiotest: image: aiotest:latest build: . prometheus.yml global: scrape_interval: 1m scrape_configs: - job_name: prometheus static_configs: - targets: [\"localhost:9090\"] # Collect resource usage and performance data of test hosts - job_name: \"192.168.0.10\" static_configs: - targets: [\"192.168.0.10:9100\"] - job_name: \"192.168.0.11\" static_configs: - targets: [\"192.168.0.11:9100\"] - job_name: \"192.168.0.12\" static_configs: - targets: [\"192.168.0.12:9100\"] - job_name: \"192.168.0.13\" static_configs: - targets: [\"192.168.0.13:9100\"] - job_name: \"192.168.0.14\" static_configs: - targets: [\"192.168.0.14:9100\"] # Collect aiotest load test data - job_name: aiotest scrape_interval: 5s static_configs: - targets: [\"192.168.0.10:8089\"] labels: instance: aiotest local-redis-stack.conf # Set a password requirepass 123456 Dockerfile FROM python:3.11-slim as base FROM base as builder RUN apt-get update && apt-get install -y git RUN python -m venv /opt/venv ENV PATH=\"/opt/venv/bin:$PATH\" COPY requirements.txt /build/requirements.txt RUN python3 -m pip install -U pip && pip install -r /build/requirements.txt FROM base COPY --from=builder /opt/venv /opt/venv ENV PATH=\"/opt/venv/bin:$PATH\" # turn off python output buffering ENV PYTHONUNBUFFERED=1 USER root WORKDIR /root/aiotest EXPOSE 8089 5557 The other hosts progressively start the node-exporter service, and build Aiotest images # 192.168.0.11 # 192.168.0.12 # 192.168.0.13 # 192.168.0.14 docker-compose -f docker-compose.yml up -d docker-compose.yml version: '3' services: node-exporter: image: prom/node-exporter:latest container_name: node-exporter user: root restart: unless-stopped volumes: - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro command: - '--path.procfs=/host/proc' - '--path.rootfs=/rootfs' - '--path.sysfs=/host/sys' - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)' ports: - 9100:9100 aiotest: image: aiotest:latest build: .","title":"Data Presentation"},{"location":"prometheus-grafana/#prometheus-and-grafana-data-presentation","text":"Use prometheus to collect aiotest test data. The default stats_exporter port is 8089 , which can be reset on the command line aiotest -f aiotestfile -p 8000","title":"Prometheus And Grafana Data Presentation"},{"location":"prometheus-grafana/#docker-deploys-jenkinsprometheusgrafanaredisaiotestnode-exporter-services","text":"Five hosts, root account, all files are in the same directory # linux host:port 192.168.0.10:22, CPU:4 docker-compose -f docker-compose.yml up -d docker-compose.yml version: '3' services: jenkins: image: jenkins/jenkins container_name: jenkins user: root restart: unless-stopped ports: - 8080:8080 - 50000:50000 volumes: - $PWD/jenkins_data:/var/jenkins_home - /var/run/docker.sock:/var/run/docker.sock - /root/.ssh:/root/.ssh prometheus: image: prom/prometheus:latest container_name: prometheus user: root restart: unless-stopped ports: - 9090:9090 command: - --config.file=/etc/prometheus/prometheus.yml volumes: - $PWD/prometheus.yml:/etc/prometheus/prometheus.yml:ro grafana: image: grafana/grafana-enterprise container_name: grafana user: root restart: unless-stopped ports: - 3000:3000 command: - --config.file=/etc/prometheus/prometheus.yml volumes: - $PWD/grafana_data:/var/lib/grafana depends_on: - prometheus redis: image: redis/redis-stack:latest container_name: redis user: root restart: unless-stopped volumes: - $PWD/redis_data/:/data - $PWD/local-redis-stack.conf:/redis-stack.conf ports: - 6379:6379 node-exporter: image: prom/node-exporter:latest container_name: node-exporter user: root restart: unless-stopped volumes: - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro command: - '--path.procfs=/host/proc' - '--path.rootfs=/rootfs' - '--path.sysfs=/host/sys' - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)' ports: - 9100:9100 aiotest: image: aiotest:latest build: . prometheus.yml global: scrape_interval: 1m scrape_configs: - job_name: prometheus static_configs: - targets: [\"localhost:9090\"] # Collect resource usage and performance data of test hosts - job_name: \"192.168.0.10\" static_configs: - targets: [\"192.168.0.10:9100\"] - job_name: \"192.168.0.11\" static_configs: - targets: [\"192.168.0.11:9100\"] - job_name: \"192.168.0.12\" static_configs: - targets: [\"192.168.0.12:9100\"] - job_name: \"192.168.0.13\" static_configs: - targets: [\"192.168.0.13:9100\"] - job_name: \"192.168.0.14\" static_configs: - targets: [\"192.168.0.14:9100\"] # Collect aiotest load test data - job_name: aiotest scrape_interval: 5s static_configs: - targets: [\"192.168.0.10:8089\"] labels: instance: aiotest local-redis-stack.conf # Set a password requirepass 123456 Dockerfile FROM python:3.11-slim as base FROM base as builder RUN apt-get update && apt-get install -y git RUN python -m venv /opt/venv ENV PATH=\"/opt/venv/bin:$PATH\" COPY requirements.txt /build/requirements.txt RUN python3 -m pip install -U pip && pip install -r /build/requirements.txt FROM base COPY --from=builder /opt/venv /opt/venv ENV PATH=\"/opt/venv/bin:$PATH\" # turn off python output buffering ENV PYTHONUNBUFFERED=1 USER root WORKDIR /root/aiotest EXPOSE 8089 5557","title":"Docker deploys jenkins,prometheus,grafana,redis,aiotest,node-exporter services"},{"location":"prometheus-grafana/#the-other-hosts-progressively-start-the-node-exporter-service-and-build-aiotest-images","text":"# 192.168.0.11 # 192.168.0.12 # 192.168.0.13 # 192.168.0.14 docker-compose -f docker-compose.yml up -d docker-compose.yml version: '3' services: node-exporter: image: prom/node-exporter:latest container_name: node-exporter user: root restart: unless-stopped volumes: - /proc:/host/proc:ro - /sys:/host/sys:ro - /:/rootfs:ro command: - '--path.procfs=/host/proc' - '--path.rootfs=/rootfs' - '--path.sysfs=/host/sys' - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)' ports: - 9100:9100 aiotest: image: aiotest:latest build: .","title":"The other hosts progressively start the node-exporter service, and build Aiotest images"},{"location":"quickstart/","text":"Your first test A Aiotest test is essentially just a Python program making requests to the system you want to test. This makes it very flexible and particularly good at implementing complex user flows. But it can do simple tests as well, so let\u2019s start with that: from aiotest import AsyncHttpUser, LoadUserShape, logger class TestUser(AsyncHttpUser): host = \"https://uat.taobao.com\" token = None async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] async def test_search(self): url = \"/search\" hearders = {\"Authorization\": self.token} data = {\"keyword\": \"F22\"} async with self.session.post(url=url, hearders=hearders, json=data) as resp: data = await resp.json() async def test_personal_info(self): url = \"/personalInfo\" async with self.session.get(url=url, hearders=hearders) as resp: data = await resp.json() This user will make HTTP requests to /search , and then /personalInfo , again and again. For a full explanation and a more realistic example see Writing a aiotestfile . Change /search and /personalInfo to some actual paths on the web site/service you want to test, put the code in a file named aiotestfile.py in your current directory and then run aiotest : $ aiotst -f aiotestfile.py 2023-09-26 11:19:35.337 | INFO | aiotest.runners:start_users:130 - starting 1 users at the rate 1 users/s, (0 users already running)... 2023-09-26 11:19:36.313 | INFO | aiotest.runners:start_users:147 - All users started: TestVipUser:1 2023-09-26 11:19:39.739 | INFO | aiotest.runners:stop_users:167 - Stopping 1 users immediately Aiotest\u2019s prometheus interface open http://localhost:8089 # HELP python_gc_objects_collected_total Objects collected during gc # TYPE python_gc_objects_collected_total counter python_gc_objects_collected_total{generation=\"0\"} 1064.0 python_gc_objects_collected_total{generation=\"1\"} 542.0 python_gc_objects_collected_total{generation=\"2\"} 0.0 # HELP python_gc_objects_uncollectable_total Uncollectable objects found during GC # TYPE python_gc_objects_uncollectable_total counter python_gc_objects_uncollectable_total{generation=\"0\"} 0.0 python_gc_objects_uncollectable_total{generation=\"1\"} 0.0 python_gc_objects_uncollectable_total{generation=\"2\"} 0.0 # HELP python_gc_collections_total Number of times this generation was collected # TYPE python_gc_collections_total counter python_gc_collections_total{generation=\"0\"} 102.0 python_gc_collections_total{generation=\"1\"} 9.0 python_gc_collections_total{generation=\"2\"} 0.0 # HELP python_info Python platform information # TYPE python_info gauge python_info{implementation=\"CPython\",major=\"3\",minor=\"11\",patchlevel=\"3\",version=\"3.11.3\"} 1.0 # HELP aiotest_workers_user_count aiotest workers user count # TYPE aiotest_workers_user_count gauge aiotest_workers_user_count{node=\"local\"} 1.0 # HELP aiotest_workers_cpu_usage aiotest workers cpu usage # TYPE aiotest_workers_cpu_usage gauge aiotest_workers_cpu_usage{node=\"Local\"} 0.3 # HELP aiotest_response_content_length aiotest response content length # TYPE aiotest_response_content_length gauge aiotest_response_content_length{code=\"200\",method=\"POST\",name=\"/login\"} 1115.0 aiotest_response_content_length{code=\"200\",method=\"POST\",name=\"/search\"} 7836.0 aiotest_response_content_length{code=\"200\",method=\"GET\",name=\"/personalInfo\"} 401.0 # HELP aiotest_response_failure_total aiotest response failure # TYPE aiotest_response_failure_total counter # HELP aiotest_user_error_total aiotest user error # TYPE aiotest_user_error_total counter # HELP aiotest_response_times aiotest response times # TYPE aiotest_response_times histogram aiotest_response_times_bucket{code=\"200\",le=\"50.0\",method=\"POST\",name=\"/login\"} 0.0 aiotest_response_times_bucket{code=\"200\",le=\"100.0\",method=\"POST\",name=\"/login\"} 0.0 aiotest_response_times_bucket{code=\"200\",le=\"200.0\",method=\"POST\",name=\"/login\"} 0.0 aiotest_response_times_bucket{code=\"200\",le=\"300.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"400.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"500.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"600.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"700.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"800.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"900.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"1000.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"2000.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"5000.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"8000.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"+Inf\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_count{code=\"200\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_sum{code=\"200\",method=\"POST\",name=\"/login\"} 277.0 aiotest_response_times_bucket{code=\"200\",le=\"50.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"100.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"200.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"300.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"400.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"500.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"600.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"700.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"800.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"900.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"1000.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"2000.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"5000.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"8000.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"+Inf\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_count{code=\"200\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_sum{code=\"200\",method=\"POST\",name=\"/search\"} 79.0 aiotest_response_times_bucket{code=\"200\",le=\"50.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"100.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"200.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"300.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"400.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"500.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"600.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"700.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"800.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"900.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"1000.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"2000.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"5000.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"8000.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"+Inf\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_count{code=\"200\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_sum{code=\"200\",method=\"GET\",name=\"/personalInfo\"} 63.0 Aiotest\u2019s grafana interface open http://localhost:3000 More options To run Aiotest distributed across multiple Python processes or machines, you start a single Aiotest master process with the --master command line parameter, and then any number of Aiotest worker processes using the --worker command line parameter. See Distributed load test for more info. To see all available options type: aiotest --help . Next steps Now, let's have a more in-depth look at aiotestfiles and what they can do: Writing a aiotestfile .","title":"Your first test"},{"location":"quickstart/#your-first-test","text":"A Aiotest test is essentially just a Python program making requests to the system you want to test. This makes it very flexible and particularly good at implementing complex user flows. But it can do simple tests as well, so let\u2019s start with that: from aiotest import AsyncHttpUser, LoadUserShape, logger class TestUser(AsyncHttpUser): host = \"https://uat.taobao.com\" token = None async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] async def test_search(self): url = \"/search\" hearders = {\"Authorization\": self.token} data = {\"keyword\": \"F22\"} async with self.session.post(url=url, hearders=hearders, json=data) as resp: data = await resp.json() async def test_personal_info(self): url = \"/personalInfo\" async with self.session.get(url=url, hearders=hearders) as resp: data = await resp.json() This user will make HTTP requests to /search , and then /personalInfo , again and again. For a full explanation and a more realistic example see Writing a aiotestfile . Change /search and /personalInfo to some actual paths on the web site/service you want to test, put the code in a file named aiotestfile.py in your current directory and then run aiotest : $ aiotst -f aiotestfile.py 2023-09-26 11:19:35.337 | INFO | aiotest.runners:start_users:130 - starting 1 users at the rate 1 users/s, (0 users already running)... 2023-09-26 11:19:36.313 | INFO | aiotest.runners:start_users:147 - All users started: TestVipUser:1 2023-09-26 11:19:39.739 | INFO | aiotest.runners:stop_users:167 - Stopping 1 users immediately","title":"Your first test"},{"location":"quickstart/#aiotests-prometheus-interface","text":"open http://localhost:8089 # HELP python_gc_objects_collected_total Objects collected during gc # TYPE python_gc_objects_collected_total counter python_gc_objects_collected_total{generation=\"0\"} 1064.0 python_gc_objects_collected_total{generation=\"1\"} 542.0 python_gc_objects_collected_total{generation=\"2\"} 0.0 # HELP python_gc_objects_uncollectable_total Uncollectable objects found during GC # TYPE python_gc_objects_uncollectable_total counter python_gc_objects_uncollectable_total{generation=\"0\"} 0.0 python_gc_objects_uncollectable_total{generation=\"1\"} 0.0 python_gc_objects_uncollectable_total{generation=\"2\"} 0.0 # HELP python_gc_collections_total Number of times this generation was collected # TYPE python_gc_collections_total counter python_gc_collections_total{generation=\"0\"} 102.0 python_gc_collections_total{generation=\"1\"} 9.0 python_gc_collections_total{generation=\"2\"} 0.0 # HELP python_info Python platform information # TYPE python_info gauge python_info{implementation=\"CPython\",major=\"3\",minor=\"11\",patchlevel=\"3\",version=\"3.11.3\"} 1.0 # HELP aiotest_workers_user_count aiotest workers user count # TYPE aiotest_workers_user_count gauge aiotest_workers_user_count{node=\"local\"} 1.0 # HELP aiotest_workers_cpu_usage aiotest workers cpu usage # TYPE aiotest_workers_cpu_usage gauge aiotest_workers_cpu_usage{node=\"Local\"} 0.3 # HELP aiotest_response_content_length aiotest response content length # TYPE aiotest_response_content_length gauge aiotest_response_content_length{code=\"200\",method=\"POST\",name=\"/login\"} 1115.0 aiotest_response_content_length{code=\"200\",method=\"POST\",name=\"/search\"} 7836.0 aiotest_response_content_length{code=\"200\",method=\"GET\",name=\"/personalInfo\"} 401.0 # HELP aiotest_response_failure_total aiotest response failure # TYPE aiotest_response_failure_total counter # HELP aiotest_user_error_total aiotest user error # TYPE aiotest_user_error_total counter # HELP aiotest_response_times aiotest response times # TYPE aiotest_response_times histogram aiotest_response_times_bucket{code=\"200\",le=\"50.0\",method=\"POST\",name=\"/login\"} 0.0 aiotest_response_times_bucket{code=\"200\",le=\"100.0\",method=\"POST\",name=\"/login\"} 0.0 aiotest_response_times_bucket{code=\"200\",le=\"200.0\",method=\"POST\",name=\"/login\"} 0.0 aiotest_response_times_bucket{code=\"200\",le=\"300.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"400.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"500.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"600.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"700.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"800.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"900.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"1000.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"2000.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"5000.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"8000.0\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_bucket{code=\"200\",le=\"+Inf\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_count{code=\"200\",method=\"POST\",name=\"/login\"} 1.0 aiotest_response_times_sum{code=\"200\",method=\"POST\",name=\"/login\"} 277.0 aiotest_response_times_bucket{code=\"200\",le=\"50.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"100.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"200.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"300.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"400.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"500.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"600.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"700.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"800.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"900.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"1000.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"2000.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"5000.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"8000.0\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"+Inf\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_count{code=\"200\",method=\"POST\",name=\"/search\"} 2.0 aiotest_response_times_sum{code=\"200\",method=\"POST\",name=\"/search\"} 79.0 aiotest_response_times_bucket{code=\"200\",le=\"50.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"100.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"200.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"300.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"400.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"500.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"600.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"700.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"800.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"900.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"1000.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"2000.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"5000.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"8000.0\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_bucket{code=\"200\",le=\"+Inf\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_count{code=\"200\",method=\"GET\",name=\"/personalInfo\"} 2.0 aiotest_response_times_sum{code=\"200\",method=\"GET\",name=\"/personalInfo\"} 63.0","title":"Aiotest\u2019s prometheus interface"},{"location":"quickstart/#aiotests-grafana-interface","text":"open http://localhost:3000","title":"Aiotest\u2019s grafana interface"},{"location":"quickstart/#more-options","text":"To run Aiotest distributed across multiple Python processes or machines, you start a single Aiotest master process with the --master command line parameter, and then any number of Aiotest worker processes using the --worker command line parameter. See Distributed load test for more info. To see all available options type: aiotest --help .","title":"More options"},{"location":"quickstart/#next-steps","text":"Now, let's have a more in-depth look at aiotestfiles and what they can do: Writing a aiotestfile .","title":"Next steps"},{"location":"running-distributed/","text":"Distributed load test A single process running Aiotest can simulate a reasonably high throughput. For a simple test plan it should be able to make many thousands of requests per second. But if you want to run even more load, you'll need to scale out to multiple processes, maybe even multiple machines. To do this, you start one instance of Aiotest in master mode using the --master flag and multiple worker instances using the --worker flag. If the workers are not on the same machine as the master you use --master-host , --master-port to point them to the IP/hostname and port of the machine running the master. The master instancetells the workers when to start/stop Users. The workers run your Users and send back statistics to the master. The master instance doesn't run any Users itself. Both the master and worker machines must have a copy of the aiotestfile when running Aiotest distributed. Note Because Python cannot fully utilize more than one core per process (see GIL , you should typically run one worker instance per processor core on the worker machines in order to utilize all their computing power. Example To start aiotest in master mode: # linux host:port 192.168.0.10:22 CPU:4 aiotest -f aiotestfile.py --master --expect-workers 8 And then on each worker (replace 192.168.0.10 with the IP of the master machine, or leave out the parameter altogether if your workers are on the same machine as the master) # linux host:port 192.168.0.11:22, CPU:4 aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" # linux host:port 192.168.0.12:22, CPU:4 aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" Options --master Sets aiotest in master mode. --worker Sets aiotest in worker mode. --master-host=X.X.X.X Optionally used together with --worker to set the hostname/IP of the master node (defaults to 127.0.0.1) --master-port=5557 Optionally used together with --worker to set the port number of the master node (defaults to 5557). --master-bind-host=X.X.X.X Optionally used together with --master . Determines which network interface the master node will bind to. Defaults to * (all available interfaces). --master-bind-port=5557 Optionally used together with --master . Determines what network ports that the master node will listen to. Defaults to 5557. --expect-workers=X Optionally used together with --master . The master node will then wait until X worker nodes has connected before the test is started. Communicating across nodes In distributed mode, it is recommended to store data in middleware redis , and each worker node pulls data from redis (for example, pull login account and login password). from redis import StrictRedis from aiotest import AsyncHttpUser db = StrictRedis( host=\"192.168.0.10\", port=\"6379\", db=0, decode_responses=True, password=\"123456\" ) pipe = db.pipeline() class TestUserShoppingTrolley(AsyncHttpUser): db = db async def on_start(self): url = \"/login\" username, password = self.db.lpop(\"userdata\") data = {\"username\": username, \"password\": password} async with self.session.post(url=url, data=data) as resp: ... Running distributed with Docker See Docker","title":"Distributed load test"},{"location":"running-distributed/#distributed-load-test","text":"A single process running Aiotest can simulate a reasonably high throughput. For a simple test plan it should be able to make many thousands of requests per second. But if you want to run even more load, you'll need to scale out to multiple processes, maybe even multiple machines. To do this, you start one instance of Aiotest in master mode using the --master flag and multiple worker instances using the --worker flag. If the workers are not on the same machine as the master you use --master-host , --master-port to point them to the IP/hostname and port of the machine running the master. The master instancetells the workers when to start/stop Users. The workers run your Users and send back statistics to the master. The master instance doesn't run any Users itself. Both the master and worker machines must have a copy of the aiotestfile when running Aiotest distributed. Note Because Python cannot fully utilize more than one core per process (see GIL , you should typically run one worker instance per processor core on the worker machines in order to utilize all their computing power.","title":"Distributed load test"},{"location":"running-distributed/#example","text":"To start aiotest in master mode: # linux host:port 192.168.0.10:22 CPU:4 aiotest -f aiotestfile.py --master --expect-workers 8 And then on each worker (replace 192.168.0.10 with the IP of the master machine, or leave out the parameter altogether if your workers are on the same machine as the master) # linux host:port 192.168.0.11:22, CPU:4 aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" # linux host:port 192.168.0.12:22, CPU:4 aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\"","title":"Example"},{"location":"running-distributed/#options","text":"--master Sets aiotest in master mode. --worker Sets aiotest in worker mode. --master-host=X.X.X.X Optionally used together with --worker to set the hostname/IP of the master node (defaults to 127.0.0.1) --master-port=5557 Optionally used together with --worker to set the port number of the master node (defaults to 5557). --master-bind-host=X.X.X.X Optionally used together with --master . Determines which network interface the master node will bind to. Defaults to * (all available interfaces). --master-bind-port=5557 Optionally used together with --master . Determines what network ports that the master node will listen to. Defaults to 5557. --expect-workers=X Optionally used together with --master . The master node will then wait until X worker nodes has connected before the test is started.","title":"Options"},{"location":"running-distributed/#communicating-across-nodes","text":"In distributed mode, it is recommended to store data in middleware redis , and each worker node pulls data from redis (for example, pull login account and login password). from redis import StrictRedis from aiotest import AsyncHttpUser db = StrictRedis( host=\"192.168.0.10\", port=\"6379\", db=0, decode_responses=True, password=\"123456\" ) pipe = db.pipeline() class TestUserShoppingTrolley(AsyncHttpUser): db = db async def on_start(self): url = \"/login\" username, password = self.db.lpop(\"userdata\") data = {\"username\": username, \"password\": password} async with self.session.post(url=url, data=data) as resp: ...","title":"Communicating across nodes"},{"location":"running-distributed/#running-distributed-with-docker","text":"See Docker","title":"Running distributed with Docker"},{"location":"running-in-command-line/","text":"Running In Command Line Stand-alone load test aiotest -f aiotestfile.py -u 100 -r 10 -t 1800 -L DEBUG --logfile logs/aiotest.log -u --users Number of concurrent users -r --rate The rate per second in which users are started/stoped -t --run-time Stop after the specified amount of time, e.g. (300s, 20m, 3h, 1h30m, etc.) -L --loglevel Choose between DEBUG/INFO/WARNING/ERROR/CRITICAL. Default is INFO. --logfile Path to log file. If not set, log will go to stdout/stderr","title":"Running In Command Line"},{"location":"running-in-command-line/#running-in-command-line","text":"Stand-alone load test aiotest -f aiotestfile.py -u 100 -r 10 -t 1800 -L DEBUG --logfile logs/aiotest.log -u --users Number of concurrent users -r --rate The rate per second in which users are started/stoped -t --run-time Stop after the specified amount of time, e.g. (300s, 20m, 3h, 1h30m, etc.) -L --loglevel Choose between DEBUG/INFO/WARNING/ERROR/CRITICAL. Default is INFO. --logfile Path to log file. If not set, log will go to stdout/stderr","title":"Running In Command Line"},{"location":"running-in-docker/","text":"Running in Docker Docker Image Use Dockerfile to create an aiotest image(assuming that the Dockerfile exists in the current working directory) Dockerfile FROM python:3.11-slim as base FROM base as builder RUN apt-get update && apt-get install -y git RUN python -m venv /opt/venv ENV PATH=\"/opt/venv/bin:$PATH\" COPY requirements.txt /build/requirements.txt RUN python3 -m pip install -U pip && pip install -r /build/requirements.txt FROM base COPY --from=builder /opt/venv /opt/venv ENV PATH=\"/opt/venv/bin:$PATH\" # turn off python output buffering ENV PYTHONUNBUFFERED=1 USER root WORKDIR /root/aiotest EXPOSE 8089 5557 # ENTRYPOINT [\"aiotest\"] # Notice the dot at the end docker build -t aiotest:v0.5.7 . Docker Compose Here's an example Docker Compose file that could be used to start both a master node, and worker nodes Distributed load test # docker-compose-master.yml version: '3' services: master: image: aiotest:0.5.7 ports: - \"8089:8089\" - \"5557:5557\" volumes: - ./:/root/aiotest command: aiotest -f aiotestfile.py --master --expect-workers 8 -d -u 8000 -r 400 -t 1800 # docker-compose-worker.yml version: '3' services: worker: image: aiotest:0.5.7 volumes: - ./:/root/aiotest command: aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" # linux host:port 192.168.0.10:22, CPU:4 # Start master node docker-compose -f docker-compose-master.yml up -d # linux host:port 192.168.0.11:22, CPU:4 # Start four worker node docker-compose -f docker-compose-worker.yml up -d --scale worker=4 # linux host:port 192.168.0.12:22, CPU:4 # Start four worker node docker-compose -f docker-compose-worker.yml up -d --scale worker=4 Stand-alone load test # docker-compose-local.yml version: '3' services: local: image: aiotest:0.5.7 ports: - \"8089:8089\" - \"5557:5557\" volumes: - ./:/root/aiotest command: aiotest -f aiotestfile.py -d -u 100 -r 10 -t 1800 # linux host:port 192.168.0.12:22, CPU:4 # Start local node docker-compose -f docker-compose-local.yml up","title":"Running in Docker"},{"location":"running-in-docker/#running-in-docker","text":"","title":"Running in Docker"},{"location":"running-in-docker/#docker-image","text":"Use Dockerfile to create an aiotest image(assuming that the Dockerfile exists in the current working directory) Dockerfile FROM python:3.11-slim as base FROM base as builder RUN apt-get update && apt-get install -y git RUN python -m venv /opt/venv ENV PATH=\"/opt/venv/bin:$PATH\" COPY requirements.txt /build/requirements.txt RUN python3 -m pip install -U pip && pip install -r /build/requirements.txt FROM base COPY --from=builder /opt/venv /opt/venv ENV PATH=\"/opt/venv/bin:$PATH\" # turn off python output buffering ENV PYTHONUNBUFFERED=1 USER root WORKDIR /root/aiotest EXPOSE 8089 5557 # ENTRYPOINT [\"aiotest\"] # Notice the dot at the end docker build -t aiotest:v0.5.7 .","title":"Docker Image"},{"location":"running-in-docker/#docker-compose","text":"Here's an example Docker Compose file that could be used to start both a master node, and worker nodes Distributed load test # docker-compose-master.yml version: '3' services: master: image: aiotest:0.5.7 ports: - \"8089:8089\" - \"5557:5557\" volumes: - ./:/root/aiotest command: aiotest -f aiotestfile.py --master --expect-workers 8 -d -u 8000 -r 400 -t 1800 # docker-compose-worker.yml version: '3' services: worker: image: aiotest:0.5.7 volumes: - ./:/root/aiotest command: aiotest -f aiotestfile.py --worker --master-host \"192.168.0.10\" # linux host:port 192.168.0.10:22, CPU:4 # Start master node docker-compose -f docker-compose-master.yml up -d # linux host:port 192.168.0.11:22, CPU:4 # Start four worker node docker-compose -f docker-compose-worker.yml up -d --scale worker=4 # linux host:port 192.168.0.12:22, CPU:4 # Start four worker node docker-compose -f docker-compose-worker.yml up -d --scale worker=4 Stand-alone load test # docker-compose-local.yml version: '3' services: local: image: aiotest:0.5.7 ports: - \"8089:8089\" - \"5557:5557\" volumes: - ./:/root/aiotest command: aiotest -f aiotestfile.py -d -u 100 -r 10 -t 1800 # linux host:port 192.168.0.12:22, CPU:4 # Start local node docker-compose -f docker-compose-local.yml up","title":"Docker Compose"},{"location":"seckill-semaphore-wait/","text":"Seckill semaphore wait In the mall test, there is a seckill scenario, customers have logged in, entered the activity page, and made all the preparations for placing orders, when it is allowed to place orders, all customers place orders at the same time. We need to have customers log in, wait for everyone to log in, and then place orders at the same time. from aiotest import AsyncHttpUser, LoadUserShape, logger, events from redis import StrictRedis from asyncio.locks import Semaphore db = StrictRedis( host=\"192.168.0.10\", port=\"6379\", db=0, decode_responses=True, password=\"123456\" ) pipe = db.pipeline() all_user_start_complete = Semaphore() all_user_start_complete.acquire() async def on_init(): db.set(\"seckill\", 1, ex=3600) async def on_start_complete(user_count, runner): if type(runner).__name__ != \"WorkerRunner\": db.set(\"seckill\", 0, ex=3600) all_user_start_complete.release() return while True: if db.get(\"seckil\") == 0: all_user_start_complete.release() return await asyncio.sleep(1) events.init += on_init events.start_complete += on_start_complete class TestUser(AsyncHttpUser): host = \"https://uat.taobao.com\" token = None async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] # Block, wait for all customers to log in all_user_start_complete.wait() async def test_search(self): url = \"/search\" hearders = {\"Authorization\": self.token} data = {\"keyword\": \"F22\"} async with self.session.post(url=url, hearders=hearders, json=data) as resp: data = await resp.json() async def test_personal_info(self): url = \"/personalInfo\" async with self.session.get(url=url, hearders=hearders) as resp: data = await resp.json()","title":"Seckill semaphore wait"},{"location":"seckill-semaphore-wait/#seckill-semaphore-wait","text":"In the mall test, there is a seckill scenario, customers have logged in, entered the activity page, and made all the preparations for placing orders, when it is allowed to place orders, all customers place orders at the same time. We need to have customers log in, wait for everyone to log in, and then place orders at the same time. from aiotest import AsyncHttpUser, LoadUserShape, logger, events from redis import StrictRedis from asyncio.locks import Semaphore db = StrictRedis( host=\"192.168.0.10\", port=\"6379\", db=0, decode_responses=True, password=\"123456\" ) pipe = db.pipeline() all_user_start_complete = Semaphore() all_user_start_complete.acquire() async def on_init(): db.set(\"seckill\", 1, ex=3600) async def on_start_complete(user_count, runner): if type(runner).__name__ != \"WorkerRunner\": db.set(\"seckill\", 0, ex=3600) all_user_start_complete.release() return while True: if db.get(\"seckil\") == 0: all_user_start_complete.release() return await asyncio.sleep(1) events.init += on_init events.start_complete += on_start_complete class TestUser(AsyncHttpUser): host = \"https://uat.taobao.com\" token = None async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] # Block, wait for all customers to log in all_user_start_complete.wait() async def test_search(self): url = \"/search\" hearders = {\"Authorization\": self.token} data = {\"keyword\": \"F22\"} async with self.session.post(url=url, hearders=hearders, json=data) as resp: data = await resp.json() async def test_personal_info(self): url = \"/personalInfo\" async with self.session.get(url=url, hearders=hearders) as resp: data = await resp.json()","title":"Seckill semaphore wait"},{"location":"testing-other-systems/","text":"testing other systems TODO","title":"Testing Other Systems"},{"location":"testing-other-systems/#testing-other-systems","text":"TODO","title":"testing other systems"},{"location":"what-is-aiotest/","text":"What is Aiotest? Aiotest is an easy to use, scriptable and scalable performance testing tool. You define the behaviour of your users in Python asyncio code, instead of being stuck in a UI or restrictive domain specific language. This makes Aiotest infinitely expandable and very developer friendly. To start using Aiotest, go to Installation Features Write test scenarios in python asyncio If you want your users to loop, perform some conditional behaviour or do some calculations, you just use the asyncio programming constructs provided by Python. Aiotest runs every user inside its task (a asyncio task). This enables you to write your tests like normal (async) Python code instead of having to use callbacks or some other mechanism. Because your scenarios are \"just python\" you can use your regular IDE, and version control your tests as regular code Distributed and scalable - supports hundreds of thousands of concurrent users Aiotest makes it easy to run load tests distributed over multiple machines. It is asyncio-based (using python asyncio , which makes it possible for a single process to handle many thousands concurrent users. While there may be other tools that are capable of doing more requests per second on a given hardware, the low overhead of each Aiotest user makes it very suitable for testing highly concurrent workloads. Command-based UI It can also be run without the UI, making it easy to use for CI/CD testing. Can test any system Even though Aiotest primarily works with web sites/services, it can be used to test almost any system or protocol. Just write a client for what you want to test Prometheus-Grafana-based Data collection and presentation Use Prometheus to collect test data and Grafana to present it Automatic collection of test cases(Reference pytest) An automatic collection of use cases similar to pytest, subclasses of User and LoadUserShape must start or end with Test(eg: TestUser,TestShape...), and api coroutines to be tested must also start or end with test(eg: test_search, test_personal_info...) Multiple user classes, flexible setting of test scenarios A aiotestfile can have multiple user classes at the same time, set different execution weights through the user class attribute weight, and flexibly set various test scenarios, example, shopping mall ordering scene, a user class simulating direct placing an order, and a user class simulating shopping cart placing an order. Custom load shapes Sometimes a completely custom shaped load test is required that cannot be achieved by simply setting or changing the user count and spawn rate. For example, you might want to generate a load spike or ramp up and down at custom times. By using a LoadUserShape class you have full control over the user count and spawn rate at all times. Serial, parallel execution of api coroutines Each user (a user class instance) acquiesce executes the test api coroutine serial from top to bottom(eg: when placing an order in the mall, the rear interface must wait for the return data from the front interface before it can be executed);You can override the self.start() method of the user class to execute the api coroutine to be tested in parallel(eg: api do not need to wait for the return data of other apis, and can be executed in parallel) Authors Hewei github mail: hewei1987@163.com License Open source licensed under the MIT license (see LICENSE file for details). Express one's thanks Aiotest is a rewrite of locust (based on python asyncio) that drops the TaskSet class, sets the API to be tested only through the User class, drops the Stats class, collects test data through Prometheus, drops the Web class, and presents test data through Grafana * locust.io","title":"What is Aiotest"},{"location":"what-is-aiotest/#what-is-aiotest","text":"Aiotest is an easy to use, scriptable and scalable performance testing tool. You define the behaviour of your users in Python asyncio code, instead of being stuck in a UI or restrictive domain specific language. This makes Aiotest infinitely expandable and very developer friendly. To start using Aiotest, go to Installation","title":"What is Aiotest?"},{"location":"what-is-aiotest/#features","text":"Write test scenarios in python asyncio If you want your users to loop, perform some conditional behaviour or do some calculations, you just use the asyncio programming constructs provided by Python. Aiotest runs every user inside its task (a asyncio task). This enables you to write your tests like normal (async) Python code instead of having to use callbacks or some other mechanism. Because your scenarios are \"just python\" you can use your regular IDE, and version control your tests as regular code Distributed and scalable - supports hundreds of thousands of concurrent users Aiotest makes it easy to run load tests distributed over multiple machines. It is asyncio-based (using python asyncio , which makes it possible for a single process to handle many thousands concurrent users. While there may be other tools that are capable of doing more requests per second on a given hardware, the low overhead of each Aiotest user makes it very suitable for testing highly concurrent workloads. Command-based UI It can also be run without the UI, making it easy to use for CI/CD testing. Can test any system Even though Aiotest primarily works with web sites/services, it can be used to test almost any system or protocol. Just write a client for what you want to test Prometheus-Grafana-based Data collection and presentation Use Prometheus to collect test data and Grafana to present it Automatic collection of test cases(Reference pytest) An automatic collection of use cases similar to pytest, subclasses of User and LoadUserShape must start or end with Test(eg: TestUser,TestShape...), and api coroutines to be tested must also start or end with test(eg: test_search, test_personal_info...) Multiple user classes, flexible setting of test scenarios A aiotestfile can have multiple user classes at the same time, set different execution weights through the user class attribute weight, and flexibly set various test scenarios, example, shopping mall ordering scene, a user class simulating direct placing an order, and a user class simulating shopping cart placing an order. Custom load shapes Sometimes a completely custom shaped load test is required that cannot be achieved by simply setting or changing the user count and spawn rate. For example, you might want to generate a load spike or ramp up and down at custom times. By using a LoadUserShape class you have full control over the user count and spawn rate at all times. Serial, parallel execution of api coroutines Each user (a user class instance) acquiesce executes the test api coroutine serial from top to bottom(eg: when placing an order in the mall, the rear interface must wait for the return data from the front interface before it can be executed);You can override the self.start() method of the user class to execute the api coroutine to be tested in parallel(eg: api do not need to wait for the return data of other apis, and can be executed in parallel)","title":"Features"},{"location":"what-is-aiotest/#authors","text":"Hewei github mail: hewei1987@163.com","title":"Authors"},{"location":"what-is-aiotest/#license","text":"Open source licensed under the MIT license (see LICENSE file for details).","title":"License"},{"location":"what-is-aiotest/#express-ones-thanks","text":"Aiotest is a rewrite of locust (based on python asyncio) that drops the TaskSet class, sets the API to be tested only through the User class, drops the Stats class, collects test data through Prometheus, drops the Web class, and presents test data through Grafana * locust.io","title":"Express one's thanks"},{"location":"writing-a-aiotestfile/","text":"Writing a aiotestfile Now, lets look at a more complete/realistic example of what your tests might look like: from aiotest import AsyncHttpUser, LoadUserShape, logger class TestUserShoppingTrolley(AsyncHttpUser): \"\"\" Get the shopping cart and submit the order \"\"\" weight = 1 wait_time = 1 host = \"https://taobao.com\" token = None orderid = None async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] async def test_get_shopping_trolley(self): url = \"/GetShoppingTrolley\" hearders = {\"Authorization\": self.token} async with self.session.get(url=url, hearders=hearders) as resp: data = await resp.json() async def order_commit_test(self): url = \"/orderCommit\" hearders = {\"Authorization\": self.token} data = {\"orderAmount\": 100, \"coupon\": 30} async with self.session.post(url=url, json=data, hearders=hearders) as resp: data = await resp.json() self.orderid = data[\"order\"][\"Orderid\"] async def test_pay(self): url = \"/Pay\" hearders = {\"Authorization\": self.token} data = {\"id\": self.orderid} async with self.session.post(url=url, json=data, headers=self.headers, name=\"My Pay\") as resp: data = await resp.json() class UserOrderCommitTest(AsyncHttpUser): \"\"\" Direct order submission \"\"\" weight = 4 wait_time = 1 host = \"https://taobao.com\" token = None orderid = None async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] async def order_commit_test(self): url = \"/orderCommit\" hearders = {\"Authorization\": self.token} data = {\"orderAmount\": 100, \"coupon\": 30} async with self.session.post(url=url, json=data, hearders=hearders) as resp: data = await resp.json() self.orderid = data[\"order\"][\"Orderid\"] async def test_pay(self): url = \"/Pay\" hearders = {\"Authorization\": self.token} data = {\"id\": self.orderid} async with self.session.post(url=url, json=data, headers=self.headers, name=\"My Pay\") as resp: data = await resp.json() Let\u2019s break it down from aiotest import AsyncHttpUser, LoadUserShape, logger A aiotest file is just a normal Python module, it can import code from other files or packages. User class TestUserShoppingTrolley(AsyncHttpUser): ... class UserOrderCommitTest(AsyncHttpUser): ... Here we define a class for the users that we will be simulating(The class must startswith or endswith Test , otherwise aiotest will ignore the class). It inherits from AsyncHttpUser which gives each user a session attribute, which is an instance of ClientSession , that can be used to make HTTP requests to the target system that we want to load test. When a test starts, aiotest will create an instance of this class for every user that it simulates, and each of these users will start running within their own asyncio.Task . For a file to be a valid aiotestfile it must contain at least one class inheriting from User wait_time wait_time = 1 Our class defines a wait_time that will make the simulated users wait 1 seconds after each api coroutine. host host = \"https://taobao.com\" The host attribute is a URL prefix to the host that is to be loaded. Usually, this is specified on the command line, using the --host option, when aiotest is started. If the command line specifies the --host attribute, it replaces the host attribute set in the user class weight class TestUserShoppingTrolley(AsyncHttpUser): weight=1 ... class UserOrderCommitTest(AsyncHttpUser): weight=4 ... We use the weight attribute to set different weights for the user class and flexibly set different load test scenarios. eg:The number of instances of the UserOrderCommitTest class would be four times that of the TestUserShoppingTrolley class. If we were to simulate 100 customers, So the UserOrderCommitTest class will instantiate 80 and the TestUserShoppingTrolley class will instantiate 20 session async with self.session.post(url=url, json=data, hearders=hearders) as resp: ... The property self.session is an instance of the ClientSession class that makes it possible to make HTTP requests that will be logged by aiotest. see more on_start() and on_stop() async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] async def on_stop(self): super().on_stop() When the user starts the operation, the on_start method will be called first, and the on_stop method will be called only once at the end. The on_start method is basically used for login and obtaining the token Job async def test_get_shopping_trolley(self): ... async def order_commit_test(self): ... Methods must startswith or endswith test ,otherwise aiotest will ignore the methods. For every running user, Aiotest creates a asyncio.Task , that will call those methods. name async def test_pay(self): ... async with self.session.post(url=url, name=\"My Pay\") as resp: ... When aiotest collects the status of each request (response_time, response_size, code), the request is named by url by default, and you can rename it by setting the parameter name in the request success() failure(exc) async def order_commit_test(self): \"The use of assert is recommended\" async with self.session.post(url=url) as resp: data = await resp.json() assert data[\"order\"][\"Orderid\"].startswith(\"2023\") async def test_pay(self): \"It is not recommended to display calls to the success,failure methods\" async with self.session.post(url=url) as resp: if resp.status < 400: resp.success() else: resp.failure(exc=\"An Error Occurred\") Use the success method to mark the request as a success, even if the response code is incorrect, and the failure method to mark the request as a failure, even if the response code is correct. When async with context exits, aiotest will automatically call the Event.stats_request and record the request information (request_name, request_method, response_time, response_length, error). It is not recommended to call the success and failure methods, it is recommended to use assert to raise an exception (see pytest )","title":"Writing a aiotestfile"},{"location":"writing-a-aiotestfile/#writing-a-aiotestfile","text":"Now, lets look at a more complete/realistic example of what your tests might look like: from aiotest import AsyncHttpUser, LoadUserShape, logger class TestUserShoppingTrolley(AsyncHttpUser): \"\"\" Get the shopping cart and submit the order \"\"\" weight = 1 wait_time = 1 host = \"https://taobao.com\" token = None orderid = None async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] async def test_get_shopping_trolley(self): url = \"/GetShoppingTrolley\" hearders = {\"Authorization\": self.token} async with self.session.get(url=url, hearders=hearders) as resp: data = await resp.json() async def order_commit_test(self): url = \"/orderCommit\" hearders = {\"Authorization\": self.token} data = {\"orderAmount\": 100, \"coupon\": 30} async with self.session.post(url=url, json=data, hearders=hearders) as resp: data = await resp.json() self.orderid = data[\"order\"][\"Orderid\"] async def test_pay(self): url = \"/Pay\" hearders = {\"Authorization\": self.token} data = {\"id\": self.orderid} async with self.session.post(url=url, json=data, headers=self.headers, name=\"My Pay\") as resp: data = await resp.json() class UserOrderCommitTest(AsyncHttpUser): \"\"\" Direct order submission \"\"\" weight = 4 wait_time = 1 host = \"https://taobao.com\" token = None orderid = None async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] async def order_commit_test(self): url = \"/orderCommit\" hearders = {\"Authorization\": self.token} data = {\"orderAmount\": 100, \"coupon\": 30} async with self.session.post(url=url, json=data, hearders=hearders) as resp: data = await resp.json() self.orderid = data[\"order\"][\"Orderid\"] async def test_pay(self): url = \"/Pay\" hearders = {\"Authorization\": self.token} data = {\"id\": self.orderid} async with self.session.post(url=url, json=data, headers=self.headers, name=\"My Pay\") as resp: data = await resp.json() Let\u2019s break it down from aiotest import AsyncHttpUser, LoadUserShape, logger A aiotest file is just a normal Python module, it can import code from other files or packages.","title":"Writing a aiotestfile"},{"location":"writing-a-aiotestfile/#user","text":"class TestUserShoppingTrolley(AsyncHttpUser): ... class UserOrderCommitTest(AsyncHttpUser): ... Here we define a class for the users that we will be simulating(The class must startswith or endswith Test , otherwise aiotest will ignore the class). It inherits from AsyncHttpUser which gives each user a session attribute, which is an instance of ClientSession , that can be used to make HTTP requests to the target system that we want to load test. When a test starts, aiotest will create an instance of this class for every user that it simulates, and each of these users will start running within their own asyncio.Task . For a file to be a valid aiotestfile it must contain at least one class inheriting from User","title":"User"},{"location":"writing-a-aiotestfile/#wait_time","text":"wait_time = 1 Our class defines a wait_time that will make the simulated users wait 1 seconds after each api coroutine.","title":"wait_time"},{"location":"writing-a-aiotestfile/#host","text":"host = \"https://taobao.com\" The host attribute is a URL prefix to the host that is to be loaded. Usually, this is specified on the command line, using the --host option, when aiotest is started. If the command line specifies the --host attribute, it replaces the host attribute set in the user class","title":"host"},{"location":"writing-a-aiotestfile/#weight","text":"class TestUserShoppingTrolley(AsyncHttpUser): weight=1 ... class UserOrderCommitTest(AsyncHttpUser): weight=4 ... We use the weight attribute to set different weights for the user class and flexibly set different load test scenarios. eg:The number of instances of the UserOrderCommitTest class would be four times that of the TestUserShoppingTrolley class. If we were to simulate 100 customers, So the UserOrderCommitTest class will instantiate 80 and the TestUserShoppingTrolley class will instantiate 20","title":"weight"},{"location":"writing-a-aiotestfile/#session","text":"async with self.session.post(url=url, json=data, hearders=hearders) as resp: ... The property self.session is an instance of the ClientSession class that makes it possible to make HTTP requests that will be logged by aiotest. see more","title":"session"},{"location":"writing-a-aiotestfile/#on_start-and-on_stop","text":"async def on_start(self): url = \"/login\" data = {\"username\": \"admin\", \"password\": \"123456\"} async with self.session.post(url=url, data=data) as resp: data = await resp.json() self.token = data[\"token\"] async def on_stop(self): super().on_stop() When the user starts the operation, the on_start method will be called first, and the on_stop method will be called only once at the end. The on_start method is basically used for login and obtaining the token","title":"on_start() and on_stop()"},{"location":"writing-a-aiotestfile/#job","text":"async def test_get_shopping_trolley(self): ... async def order_commit_test(self): ... Methods must startswith or endswith test ,otherwise aiotest will ignore the methods. For every running user, Aiotest creates a asyncio.Task , that will call those methods.","title":"Job"},{"location":"writing-a-aiotestfile/#name","text":"async def test_pay(self): ... async with self.session.post(url=url, name=\"My Pay\") as resp: ... When aiotest collects the status of each request (response_time, response_size, code), the request is named by url by default, and you can rename it by setting the parameter name in the request","title":"name"},{"location":"writing-a-aiotestfile/#success-failureexc","text":"async def order_commit_test(self): \"The use of assert is recommended\" async with self.session.post(url=url) as resp: data = await resp.json() assert data[\"order\"][\"Orderid\"].startswith(\"2023\") async def test_pay(self): \"It is not recommended to display calls to the success,failure methods\" async with self.session.post(url=url) as resp: if resp.status < 400: resp.success() else: resp.failure(exc=\"An Error Occurred\") Use the success method to mark the request as a success, even if the response code is incorrect, and the failure method to mark the request as a failure, even if the response code is correct. When async with context exits, aiotest will automatically call the Event.stats_request and record the request information (request_name, request_method, response_time, response_length, error). It is not recommended to call the success and failure methods, it is recommended to use assert to raise an exception (see pytest )","title":"success() failure(exc)"}]}